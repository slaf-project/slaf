<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <link rel="icon" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.14.0/dist/favicon.ico" />
    <!-- Preload is necessary because we show these images when we disconnect from the server,
    but at that point we cannot load these images from the server -->
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.14.0/dist/assets/gradient-yHQUC_QB.png" as="image" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.14.0/dist/assets/noise-60BoTA8O.png" as="image" />
    <!-- Preload the fonts -->
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.14.0/dist/assets/Lora-VariableFont_wght-B2ootaw-.ttf" as="font" crossorigin="anonymous" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.14.0/dist/assets/PTSans-Regular-CxL0S8W7.ttf" as="font" crossorigin="anonymous" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.14.0/dist/assets/PTSans-Bold-D9fedIX3.ttf" as="font" crossorigin="anonymous" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.14.0/dist/assets/FiraMono-Regular-BTCkDNvf.ttf" as="font" crossorigin="anonymous" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.14.0/dist/assets/FiraMono-Medium-DU3aDxX5.ttf" as="font" crossorigin="anonymous" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.14.0/dist/assets/FiraMono-Bold-CLVRCuM9.ttf" as="font" crossorigin="anonymous" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="theme-color" content="#000000" />
    <meta name="description" content="a marimo app" />
    <link rel="apple-touch-icon" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.14.0/dist/apple-touch-icon.png" />
    <link rel="manifest" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.14.0/dist/manifest.json" />

    <script data-marimo="true">
      function __resizeIframe(obj) {
        var scrollbarHeight = 20; // Max between windows, mac, and linux

        function setHeight() {
          var element = obj.contentWindow.document.documentElement;
          // If there is no vertical scrollbar, we don't need to resize the iframe
          if (element.scrollHeight === element.clientHeight) {
            return;
          }

          // Create a new height that includes the scrollbar height if it's visible
          var hasHorizontalScrollbar = element.scrollWidth > element.clientWidth;
          var newHeight = element.scrollHeight + (hasHorizontalScrollbar ? scrollbarHeight : 0);

          // Only update the height if it's different from the current height
          if (obj.style.height !== `${newHeight}px`) {
            obj.style.height = `${newHeight}px`;
          }
        }

        // Resize the iframe to the height of the content and bottom scrollbar height
        setHeight();

        // Resize the iframe when the content changes
        const resizeObserver = new ResizeObserver((entries) => {
          setHeight();
        });
        resizeObserver.observe(obj.contentWindow.document.body);
      }
    </script>
    <marimo-filename hidden>03-ml-training-pipeline.py</marimo-filename>
    <title>03-ml-training-pipeline</title>
    <script type="module" crossorigin crossorigin="anonymous" src="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.14.0/dist/assets/index-_Zd2Tjcq.js"></script>
    <link rel="stylesheet" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.14.0/dist/assets/index-BVt8Dtzn.css">

<script data-marimo="true">
    window.__MARIMO_STATIC__ = {};
    window.__MARIMO_STATIC__.files = {};
</script>
</head>
  <body>
    <div id="root"></div>
    <script data-marimo="true">
      window.__MARIMO_MOUNT_CONFIG__ = {
            "filename": "03-ml-training-pipeline.py",
            "mode": "read",
            "version": "0.14.0",
            "serverToken": "static",
            "config": {"completion": {"activate_on_typing": true, "copilot": false}, "display": {"cell_output": "above", "code_editor_font_size": 14, "dataframes": "rich", "default_table_page_size": 10, "default_width": "medium", "theme": "light"}, "formatting": {"line_length": 79}, "keymap": {"overrides": {}, "preset": "default"}, "language_servers": {"pylsp": {"enable_flake8": false, "enable_mypy": true, "enable_pydocstyle": false, "enable_pyflakes": false, "enable_pylint": false, "enable_ruff": true, "enabled": true}}, "package_management": {"manager": "pip"}, "runtime": {"auto_instantiate": true, "auto_reload": "off", "default_sql_output": "auto", "on_cell_change": "autorun", "output_max_bytes": 8000000, "reactive_tests": true, "std_stream_max_bytes": 1000000, "watcher_on_save": "lazy"}, "save": {"autosave": "after_delay", "autosave_delay": 1000, "format_on_save": false}, "server": {"browser": "default", "follow_symlink": false}, "snippets": {"custom_paths": [], "include_default_snippets": true}},
            "configOverrides": {},
            "appConfig": {"sql_output": "auto", "width": "medium"},
            "view": {"showAppCode": true},
            "notebook": {"cells": [{"code": "import time\n\nimport marimo as mo\nimport numpy as np\n\nfrom slaf import SLAFArray\nfrom slaf.ml.dataloaders import SLAFDataLoader\nfrom slaf.ml.tokenizers import SLAFTokenizer\n", "code_hash": "72bd3eb48288fa44e643be397d86a48d", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "Hbol", "name": "_"}, {"code": "mo.md(\n    \"\"\"\n# SLAF ML Training Pipeline\n\nThis notebook demonstrates how to build complete ML training pipelines with SLAF, including:\n\n- Custom tokenizer configuration\n\n- Different tokenization strategies (scGPT, Geneformer)\n\n- DataLoader integration with PyTorch\n\n- Performance optimization techniques\n\n- Custom training loop examples\n\n**Key Benefits for ML Training:**\n\n\ud83d\ude80 **Fast Tokenization**: SQL-level performance for token generation\n\n\ud83d\udcbe **Memory Efficient**: Stream data without loading everything into memory\n\n\ud83d\udd04 **Flexible**: Support for different tokenization strategies and model architectures\n\n\ud83e\uddec **Production Ready**: Built for large-scale training with proper splits and error handling\n\n\u26a1 **Optimized**: SQL binning, percentile filtering, and other performance optimizations\n\"\"\"\n)", "code_hash": "2a896a97387b10cc623231a5dd440273", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "MJUe", "name": "_"}, {"code": "# Load SLAF dataset for ML examples\nslaf = SLAFArray(\"../slaf-datasets/pbmc3k_processed.slaf\")\nprint(f\"\u2705 Loaded SLAF dataset: {slaf.shape[0]:,} cells \u00d7 {slaf.shape[1]:,} genes\")\n\n# Show dataset info\nslaf.info()", "code_hash": "11e373832fc301071b83d550f10621c3", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "vblA", "name": "_"}, {"code": "mo.md(\n    \"\"\"\n## 1. Understanding SLAF Tokenization\n\nSLAF provides efficient tokenization for single-cell data, supporting multiple strategies:\n\"\"\"\n)", "code_hash": "baad5c54234ca597715c5d34701b941d", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "bkHC", "name": "_"}, {"code": "mo.md(r\"\"\"### Tokenizer Configuration\"\"\")", "code_hash": "ef422617146b4f7876898bfbff2f293e", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "lEQa", "name": "_"}, {"code": "# Create tokenizer with custom settings\ntokenizer = SLAFTokenizer(\n    slaf_array=slaf,\n    vocab_size=5000,  # Smaller vocab for demo\n    n_expression_bins=20,  # More expression bins\n    chunk_size=512,  # Smaller chunks for memory efficiency\n)\n\n# Get vocabulary information\nvocab_info = tokenizer.get_vocab_info()\nprint(\"\u2705 Tokenizer initialized:\")\nprint(f\"   Total vocabulary size: {vocab_info['total_vocab_size']:,}\")\nprint(f\"   Special tokens: {vocab_info['special_tokens']}\")\nprint(f\"   Expression bins: {vocab_info['n_expression_bins']}\")\nprint(f\"   Gene vocabulary size: {vocab_info['vocab_size']:,}\")\n\n# Show special tokens\nprint(\"\\nSpecial tokens:\")\nfor token_name, token_id in tokenizer.special_tokens.items():\n    print(f\"   {token_name}: {token_id}\")\n", "code_hash": "92bd590923a6d488a2f750f269058d11", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "PKri", "name": "_"}, {"code": "mo.md(\n    \"\"\"\n## 2. Tokenization Strategies\n\nSLAF supports different tokenization strategies for different model architectures:\n\"\"\"\n)", "code_hash": "791464f54081db5ad49cad5e4a233b75", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "Xref", "name": "_"}, {"code": "mo.md(r\"\"\"### Geneformer and scGPT style tokenization\"\"\")", "code_hash": "9daede8d407089963c076ad00b9ee3a6", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "SFPL", "name": "_"}, {"code": "# Tokenize a small batch of cells for demonstration\n\n# 1. Geneformer tokenization\nprint(\"\\n1. Geneformer Tokenization:\")\nprint(\"   Format: [gene1, gene2, gene3, ...] (sorted by expression)\")\n\ngeneformer_tokens = tokenizer.tokenize_geneformer(\n    cell_integer_id_range=(0, 10),  # Limit for demo\n    max_genes=50,  # Limit for demo\n    min_percentile=10,  # Filter low-expression genes\n)\n\nprint(\n    f\"   Generated {len(geneformer_tokens)} sequences of length {len(geneformer_tokens[0])}\"\n)\n\n# 2. scGPT tokenization\nprint(\"\\n2. scGPT Tokenization:\")\nprint(\"   Format: [CLS] gene1 expr1 gene2 expr2 ... [SEP]\")\n\nscgpt_tokens = tokenizer.tokenize_scgpt(\n    cell_integer_id_range=(0, 10),  # Limit for demo (scGPT sequences are longer)\n    max_genes=25,  # Limit for demo (scGPT sequences are longer)\n    use_sql_binning=True,  # Use SQL for better performance\n)\n\nprint(\n    f\"   Generated {len(scgpt_tokens)} sequences of length {len(scgpt_tokens[0])}\"\n)\n", "code_hash": "5dc85de5528ea0b16d6be8c4e3a39a91", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "BYtC", "name": "_"}, {"code": "mo.md(r\"\"\"### Token decoding examples\"\"\")", "code_hash": "8b92c64b12c42886b6c9a7181d4cec91", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "RGSE", "name": "_"}, {"code": "# Demonstrate token decoding\nif geneformer_tokens:\n    print(\"1. Geneformer sequence decoding:\")\n    decoded_geneformer = tokenizer.decode_tokens(geneformer_tokens[0])\n    print(f\"   Sequence length: {len(geneformer_tokens[0])}\")\n    print(f\"   Genes: {len(decoded_geneformer['genes'])} genes\")\n    if decoded_geneformer[\"genes\"]:\n        print(f\"   First few genes: {decoded_geneformer['genes'][:3]}\")\n\nif scgpt_tokens:\n    print(\"\\n2. scGPT sequence decoding:\")\n    decoded_scgpt = tokenizer.decode_tokens(scgpt_tokens[0])\n    print(f\"   Sequence length: {len(scgpt_tokens[0])}\")\n    print(f\"   Special tokens: {decoded_scgpt['special_tokens']}\")\n    print(f\"   Genes: {len(decoded_scgpt['genes'])} genes\")\n    print(f\"   Expression bins: {len(decoded_scgpt['expression_bins'])} bins\")\n    if decoded_scgpt[\"genes\"]:\n        print(f\"   First few genes: {decoded_scgpt['genes'][:3]}\")\n        print(\n            f\"   First few expression bins: {decoded_scgpt['expression_bins'][:3]}\"\n        )\n", "code_hash": "abb2ff5dc1d64bfa0d754c6883fbbf58", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "Kclp", "name": "_"}, {"code": "mo.md(\n    \"\"\"\n## 3. Performance Comparison - Different Tokenization Approaches\n\nLet's compare the performance of different tokenization strategies:\n\"\"\"\n)", "code_hash": "135518d0ce6c8e15f92f65d4d88ebf31", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "emfo", "name": "_"}, {"code": "class Timer:\n    def __init__(self, name=None):\n        self.name = name\n        self.elapsed = 0.0\n        self._start_time = None\n\n    def __enter__(self):\n        self._start_time = (\n            time.perf_counter()\n        )  # Use perf_counter for more accurate timing\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        if self._start_time is not None:\n            end_time = time.perf_counter()\n            self.elapsed = end_time - self._start_time\n\n# Usage\nwith Timer(\"My Task\") as t:\n    # Code to be timed\n    time.sleep(2)  # Simulate some work\n    print(\"Task completed\")\n\nprint(f\"Elapsed time captured from context manager object: {t.elapsed:.4f} seconds\")\n", "code_hash": "8d888c7fd6e32b90f8328bc22e2e17db", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "Hstk", "name": "_"}, {"code": "# Performance comparison\nprint(\"\u26a1 Tokenization Performance Comparison\")\nprint(\"=\" * 45)\n\ndef demo_tokenizer_performance():\n    # Test Geneformer with 100 cells\n    print(\"\\n1. Geneformer Performance:\")\n\n    # Standard Geneformer\n    with Timer(\"geneformer_standard\") as standard_time:\n        geneformer_standard = tokenizer.tokenize_geneformer(\n            (0, 100), max_genes=100, min_percentile=None\n        )\n\n    print(f\"    Geneformer [standard]: {standard_time.elapsed:.4f}s\")\n    # Geneformer with percentile filtering\n    with Timer(\"geneformer_percentile\") as percentile_time:\n        _ = tokenizer.tokenize_geneformer(\n            (0, 100), max_genes=100, min_percentile=10\n        )\n    print(f\"   Geneformer [percentile]: {percentile_time.elapsed:.4f}s\")\n    print(f\"   Speedup: {standard_time.elapsed / percentile_time.elapsed:.2f}x\")\n\n    # Test scGPT with different settings\n    print(\"\\n2. scGPT Performance:\")\n\n    # scGPT with Python binning\n    with Timer(\"scgpt_python\") as python_time:\n        _ = tokenizer.tokenize_scgpt((0, 100), max_genes=50, use_sql_binning=False)\n    print(f\"   scGPT [Python]: {python_time.elapsed:.4f}s\")\n\n    # scGPT with SQL binning\n    with Timer(\"scgpt_sql\") as sql_time:\n        scgpt_sql = tokenizer.tokenize_scgpt(\n            (0, 100), max_genes=50, use_sql_binning=True\n        )\n    print(f\"   scGPT [SQL]: {sql_time.elapsed:.4f}s\")\n    print(f\"   Speedup: {python_time.elapsed / sql_time.elapsed:.2f}x\")\n\n    # Calculate tokens per second\n    total_tokens_geneformer = sum(len(seq) for seq in geneformer_standard)\n    total_tokens_scgpt = sum(len(seq) for seq in scgpt_sql)\n\n    print(\"\\n3. Throughput:\")\n    print(\n        f\"   Geneformer [standard]: {total_tokens_geneformer / standard_time.elapsed:,.0f} tokens/sec\"\n    )\n    print(\n        f\"   Geneformer [percentile]: {total_tokens_geneformer / percentile_time.elapsed:,.0f} tokens/sec\"\n    )\n    print(\n        f\"   scGPT [Python]: {total_tokens_scgpt / python_time.elapsed:,.0f} tokens/sec\"\n    )\n    print(\n        f\"   scGPT [SQL]: {total_tokens_scgpt / sql_time.elapsed:,.0f} tokens/sec\"\n    )\n\ndemo_tokenizer_performance()", "code_hash": "2bebd602c2886c2ca5bf541f3b9e8cf9", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "nWHF", "name": "_"}, {"code": "mo.md(\n    \"\"\"\n## 4. SLAF DataLoader - Production-Ready Training\n\nSLAF provides a high-performance DataLoader for training:\n\"\"\"\n)", "code_hash": "50f70483b9ee433c38f0251d5dc6e8e7", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "iLit", "name": "_"}, {"code": "# Initialize DataLoader\nprint(\"\ud83d\udce6 SLAF DataLoader Configuration\")\nprint(\"=\" * 40)\n\n# Create DataLoader with custom settings\ndataloader = SLAFDataLoader(\n    slaf_array=slaf,\n    tokenizer_type=\"geneformer\",  # or \"scgpt\"\n    batch_size=16,  # Small batch for demo\n    max_genes=100,\n    num_workers=2,  # Number of worker processes\n    vocab_size=5000,\n    n_expression_bins=20,\n    chunk_size=512,\n)\n\nprint(\"\u2705 DataLoader initialized:\")\nprint(f\"   Tokenizer type: {dataloader.tokenizer_type}\")\nprint(f\"   Batch size: {dataloader.batch_size}\")\nprint(f\"   Max genes: {dataloader.max_genes}\")\nprint(f\"   Number of batches: {len(dataloader)}\")\nprint(f\"   Special tokens: {dataloader.special_tokens}\")\n", "code_hash": "0aa79ddc456736912c954453423d901c", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "ZHCJ", "name": "_"}, {"code": "# Demonstrate DataLoader iteration\nprint(\"\ud83d\udd04 DataLoader Iteration\")\nprint(\"=\" * 25)\n\ndef demo_dataloader_iteration(dataloader):\n    # Get first batch\n    print(\"1. First batch structure:\")\n    batch = next(iter(dataloader))\n\n    for key, value in batch.items():\n        if hasattr(value, \"shape\"):\n            print(f\"   {key}: {type(value)} with shape {value.shape}\")\n        else:\n            print(f\"   {key}: {type(value)} with length {len(value)}\")\n\n    # Show batch details\n    input_ids = batch[\"input_ids\"]\n    attention_mask = batch[\"attention_mask\"]\n    cell_ids = batch[\"cell_ids\"]\n\n    print(\"\\n2. Batch details:\")\n    print(f\"   Input IDs shape: {input_ids.shape}\")\n    print(f\"   Attention mask shape: {attention_mask.shape}\")\n    print(f\"   Cell IDs shape: {cell_ids.shape}\")\n    print(f\"   Data type: {input_ids.dtype}\")\n\n    # Show sample tokens\n    print(\"\\n3. Sample tokens from first sequence:\")\n    first_seq = input_ids[0]\n    print(f\"   First 10 tokens: {first_seq[:10].tolist()}\")\n    print(f\"   Sequence length: {len(first_seq)}\")\n\ndemo_dataloader_iteration(dataloader)", "code_hash": "938b9ca6b14553bd608d5e14ae57bceb", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "ROlb", "name": "_"}, {"code": "# Performance testing of DataLoader\nprint(\"\u26a1 DataLoader Performance\")\nprint(\"=\" * 30)\n\n# Test iteration speed\nprint(\"1. Iteration performance:\")\n\ndef demo_dataloader_iteration_performance():\n    batch_count = 0\n    total_tokens = 0\n\n    for batch in dataloader:\n        batch_count += 1\n        total_tokens += batch[\"input_ids\"].shape[0] * batch[\"input_ids\"].shape[1]\n\n        # Only process first few batches for demo\n        if batch_count >= 5:\n            break\n    return batch_count, total_tokens\n\nwith Timer(\"dataloader_iteration\") as iteration_time:\n    batch_count, total_tokens = demo_dataloader_iteration_performance()\n\nprint(f\"   Processed {batch_count} batches in {iteration_time.elapsed:.4f}s\")\nprint(f\"   Total tokens: {total_tokens:,}\")\nprint(f\"   Tokens per second: {total_tokens / iteration_time.elapsed:,.0f}\")\nprint(f\"   Batches per second: {batch_count / iteration_time.elapsed:.2f}\")\n", "code_hash": "e947ddb4d19a29ecef9e2ffb10c3ee27", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "qnkX", "name": "_"}, {"code": "mo.md(\n    \"\"\"\n## 5. PyTorch Training Loop Integration\n\nHere's how to integrate SLAF DataLoader with PyTorch training:\n\"\"\"\n)", "code_hash": "974e2b150b9e598622d517545e946b26", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "TqIu", "name": "_"}, {"code": "# Demonstrate PyTorch integration\nprint(\"\ud83d\udd25 PyTorch Training Loop Integration\")\nprint(\"=\" * 45)\n\ndef demo_training_loop(dataloader):\n    # Check if PyTorch is available\n    try:\n        import torch\n\n        TORCH_AVAILABLE = True\n        print(\"\u2705 PyTorch is available\")\n    except ImportError:\n        TORCH_AVAILABLE = False\n        print(\"\u26a0\ufe0f PyTorch not available - showing numpy-based approach\")\n\n    if TORCH_AVAILABLE:\n        print(\"\\n1. PyTorch tensor conversion:\")\n        batch = next(iter(dataloader))\n\n        # Get device info\n        from slaf.ml.dataloaders import get_device_info, get_optimal_device\n\n        device_info = get_device_info()\n        optimal_device = get_optimal_device()\n\n        print(f\"   Device info: {device_info}\")\n        print(f\"   Using device: {optimal_device}\")\n\n        # Convert to PyTorch tensors on optimal device\n        input_ids_tensor = torch.tensor(\n            batch[\"input_ids\"], dtype=torch.long, device=optimal_device\n        )\n        attention_mask_tensor = torch.tensor(\n            batch[\"attention_mask\"], dtype=torch.bool, device=optimal_device\n        )\n        cell_ids_tensor = torch.tensor(\n            batch[\"cell_ids\"], dtype=torch.long, device=optimal_device\n        )\n\n        print(\n            f\"   Input IDs tensor: {input_ids_tensor.shape}, {input_ids_tensor.dtype}\"\n        )\n        print(\n            f\"   Attention mask tensor: {attention_mask_tensor.shape}, {attention_mask_tensor.dtype}\"\n        )\n        print(\n            f\"   Cell IDs tensor: {cell_ids_tensor.shape}, {cell_ids_tensor.dtype}\"\n        )\n\n        print(\"\\n2. Simple training loop structure:\")\n        print(\n            \"\"\"\n        # Training loop example with smart device detection\n        from slaf.ml.dataloaders import get_optimal_device\n\n        device = get_optimal_device()\n        model = YourModel(vocab_size=tokenizer.get_vocab_info()['total_vocab_size'])\n        model = model.to(device)  # Move model to optimal device\n        optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n\n        for epoch in range(num_epochs):\n            model.train()\n            for batch in dataloader:\n                # DataLoader already provides tensors on optimal device\n                input_ids = batch[\"input_ids\"]  # Already on device\n                attention_mask = batch[\"attention_mask\"]  # Already on device\n\n                # Forward pass\n                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n                loss = outputs.loss\n\n                # Backward pass\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n        \"\"\"\n        )\n\n    else:\n        print(\"\\n1. Numpy-based approach:\")\n        batch = next(iter(dataloader))\n        print(\n            f\"   Input IDs: {batch['input_ids'].shape}, {batch['input_ids'].dtype}\"\n        )\n        print(\n            f\"   Attention mask: {batch['attention_mask'].shape}, {batch['attention_mask'].dtype}\"\n        )\n        print(f\"   Cell IDs: {batch['cell_ids'].shape}, {batch['cell_ids'].dtype}\")\n\ndemo_training_loop(dataloader)", "code_hash": "7f57a87999880983a2e1f21b81b31f62", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "Vxnm", "name": "_"}, {"code": "mo.md(\n    \"\"\"\n## 6. Custom DataLoader Implementation\n\nLearn how to create custom DataLoaders for specific use cases:\n\"\"\"\n)", "code_hash": "23b837624558d53057d2ef4e4ae9d63f", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "DnEU", "name": "_"}, {"code": "# Custom DataLoader implementation\nprint(\"\ud83d\udd27 Custom DataLoader Implementation\")\nprint(\"=\" * 40)\n\nclass CustomSLAFDataLoader:\n    \"\"\"Custom DataLoader with specific functionality\"\"\"\n\n    def __init__(\n        self,\n        slaf_array,\n        batch_size=32,\n        max_genes=100,\n        tokenizer_type=\"geneformer\",\n        **tokenizer_kwargs,\n    ):\n        self.slaf_array = slaf_array\n        self.batch_size = batch_size\n        self.max_genes = max_genes\n        self.tokenizer_type = tokenizer_type\n\n        # Initialize tokenizer\n        self.tokenizer = SLAFTokenizer(slaf_array, **tokenizer_kwargs)\n\n        # Get cell ranges for batching\n        self.cell_ranges = self._get_cell_ranges()\n\n    def _get_cell_ranges(self):\n        \"\"\"Get cell integer ID ranges for batching\"\"\"\n        max_cell_id = int(self.slaf_array.obs[\"cell_integer_id\"].astype(int).max())\n        ranges = []\n        for start in range(0, max_cell_id + 1, self.batch_size):\n            end = min(start + self.batch_size, max_cell_id + 1)\n            ranges.append((start, end))\n        return ranges\n\n    def __iter__(self):\n        \"\"\"Iterate through batches\"\"\"\n        for cell_range in self.cell_ranges:\n            # Tokenize based on type\n            if self.tokenizer_type == \"geneformer\":\n                tokens = self.tokenizer.tokenize_geneformer(\n                    cell_integer_id_range=cell_range, max_genes=self.max_genes\n                )\n            elif self.tokenizer_type == \"scgpt\":\n                tokens = self.tokenizer.tokenize_scgpt(\n                    cell_integer_id_range=cell_range, max_genes=self.max_genes\n                )\n            else:\n                raise ValueError(f\"Unknown tokenizer type: {self.tokenizer_type}\")\n\n            if not tokens:\n                continue\n\n            # Convert to numpy arrays\n            batch_tensors = np.array(tokens, dtype=np.int64)\n            attention_mask = batch_tensors != self.tokenizer.special_tokens[\"PAD\"]\n\n            # Get cell IDs for this range\n            start_cell, end_cell = cell_range\n            cell_ids = list(range(start_cell, end_cell))\n\n            yield {\n                \"input_ids\": batch_tensors,\n                \"attention_mask\": attention_mask,\n                \"cell_ids\": np.array(cell_ids[: len(tokens)], dtype=np.int64),\n            }\n\n    def __len__(self):\n        return len(self.cell_ranges)\n\n# Test custom DataLoader\nprint(\"\u2705 Custom DataLoader created\")\n\ncustom_dataloader = CustomSLAFDataLoader(\n    slaf_array=slaf,\n    batch_size=8,\n    max_genes=50,\n    tokenizer_type=\"geneformer\",\n    vocab_size=1000,\n)\n\nprint(f\"   Number of batches: {len(custom_dataloader)}\")\n\n# Test iteration\nbatch = next(iter(custom_dataloader))\nprint(f\"   First batch shape: {batch['input_ids'].shape}\")\n", "code_hash": "97177f0678804cb6731b2245019f4646", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "ulZA", "name": "_"}, {"code": "mo.md(\n    \"\"\"\n## 7. Advanced Tokenization Features\n\nExplore advanced tokenization features and optimizations:\n\"\"\"\n)", "code_hash": "386d06b7004b213dcdae8da48515cc39", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "ecfG", "name": "_"}, {"code": "# Advanced tokenization features\nprint(\"\ud83d\ude80 Advanced Tokenization Features\")\nprint(\"=\" * 40)\n\ndef demo_advanced_tokenization():\n    print(\"1. Different max_genes settings:\")\n    for max_genes in [25, 50, 100]:\n        tokens = tokenizer.tokenize_geneformer((0, 20), max_genes=max_genes)\n        avg_length = np.mean([len(seq) for seq in tokens])\n        print(f\"   max_genes={max_genes}: avg_length={avg_length:.1f}\")\n\n    print(\"\\n2. Different percentile filtering:\")\n    for percentile in [None, 5, 10, 20]:\n        tokens = tokenizer.tokenize_geneformer(\n            (0, 20), max_genes=50, min_percentile=percentile\n        )\n        avg_length = np.mean([len(seq) for seq in tokens])\n        print(f\"   min_percentile={percentile}: avg_length={avg_length:.1f}\")\n\n    print(\"\\n3. SQL vs Python binning for scGPT:\")\n    # SQL binning\n    start_time = time.time()\n    _ = tokenizer.tokenize_scgpt((0, 20), max_genes=25, use_sql_binning=True)\n    sql_time = time.time() - start_time\n\n    # Python binning\n    start_time = time.time()\n    _ = tokenizer.tokenize_scgpt((0, 20), max_genes=25, use_sql_binning=False)\n    python_time = time.time() - start_time\n\n    print(f\"   SQL binning: {sql_time:.4f}s\")\n    print(f\"   Python binning: {python_time:.4f}s\")\n    print(f\"   Speedup: {python_time / sql_time:.2f}x\")\n\ndemo_advanced_tokenization()", "code_hash": "dca66eb285875acfc59a47cbc6584cb1", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "Pvdt", "name": "_"}, {"code": "mo.md(\n    \"\"\"\n## 8. Memory and Performance Optimization\n\nLearn how to optimize memory usage and performance for large-scale training:\n\"\"\"\n)", "code_hash": "1b959440c168991765eb13f6be153e02", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "ZBYS", "name": "_"}, {"code": "# Memory and performance optimization\nprint(\"\ud83d\udcbe Memory and Performance Optimization\")\nprint(\"=\" * 45)\n\nimport gc\n\nimport psutil\n\ndef get_memory_usage():\n    \"\"\"Get current memory usage in MB\"\"\"\n    process = psutil.Process()\n    return process.memory_info().rss / 1024 / 1024\n\ndef demo_memory_and_performance_optimization():\n    print(\"1. Memory usage comparison:\")\n\n    # Baseline memory\n    gc.collect()\n    baseline_memory = get_memory_usage()\n    print(f\"   Baseline memory: {baseline_memory:.1f} MB\")\n\n    # Memory with different batch sizes\n    for batch_size in [8, 16, 32]:\n        gc.collect()\n        start_memory = get_memory_usage()\n\n        dataloader = SLAFDataLoader(\n            slaf_array=slaf, batch_size=batch_size, max_genes=100, vocab_size=1000\n        )\n\n        # Process one batch\n        _ = next(iter(dataloader))\n        end_memory = get_memory_usage()\n\n        print(\n            f\"   Batch size {batch_size}: {end_memory:.1f} MB (+{end_memory - start_memory:.1f} MB)\"\n        )\n\n    print(\"\\n2. Performance with different settings:\")\n\n    # Test different configurations\n    configs = [\n        {\"batch_size\": 8, \"max_genes\": 50, \"description\": \"Small batches\"},\n        {\"batch_size\": 16, \"max_genes\": 100, \"description\": \"Medium batches\"},\n        {\"batch_size\": 32, \"max_genes\": 200, \"description\": \"Large batches\"},\n    ]\n\n    for config in configs:\n        dataloader = SLAFDataLoader(\n            slaf_array=slaf,\n            **{k: v for k, v in config.items() if k != \"description\"},\n        )\n\n        start_time = time.time()\n        batch_count = 0\n        for _ in dataloader:\n            batch_count += 1\n            if batch_count >= 3:  # Test first 3 batches\n                break\n\n        elapsed_time = time.time() - start_time\n        print(\n            f\"   {config['description']}: {elapsed_time:.4f}s for {batch_count} batches\"\n        )\n\ndemo_memory_and_performance_optimization()", "code_hash": "e0804bfd0beaaddba7f80b3c86d39fa7", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "aLJB", "name": "_"}, {"code": "mo.md(\n    \"\"\"\n## 9. Production Training Workflow\n\nComplete example of a production-ready training workflow:\n\"\"\"\n)", "code_hash": "8258f9bc568b2c9517ec0f036e28adba", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "nHfw", "name": "_"}, {"code": "# Production training workflow\nprint(\"\ud83c\udfed Production Training Workflow\")\nprint(\"=\" * 40)\n\ndef create_production_dataloaders(\n    slaf_array, train_ratio=0.8, val_ratio=0.1, test_ratio=0.1\n):\n    \"\"\"Create train/val/test dataloaders\"\"\"\n\n    # Get total number of cells\n    total_cells = len(slaf_array.obs)\n    _ = int(total_cells * train_ratio)  # train_size\n    _ = int(total_cells * val_ratio)  # val_size\n\n    # Create tokenizer\n    tokenizer = SLAFTokenizer(\n        slaf_array=slaf_array,\n        vocab_size=10000,\n        n_expression_bins=50,\n        chunk_size=1024,\n    )\n\n    print(\n        f\"\u2705 Created tokenizer with {tokenizer.get_vocab_info()['total_vocab_size']} total tokens\"\n    )\n\n    # Create dataloaders (in production, you'd use proper splits)\n    train_dataloader = SLAFDataLoader(\n        slaf_array=slaf_array,\n        tokenizer_type=\"geneformer\",\n        batch_size=32,\n        max_genes=512,\n        vocab_size=10000,\n        n_expression_bins=50,\n    )\n\n    val_dataloader = SLAFDataLoader(\n        slaf_array=slaf_array,\n        tokenizer_type=\"geneformer\",\n        batch_size=32,\n        max_genes=512,\n        vocab_size=10000,\n        n_expression_bins=50,\n    )\n\n    return train_dataloader, val_dataloader, tokenizer\n\n# Create production dataloaders\ntrain_dl, val_dl, prod_tokenizer = create_production_dataloaders(slaf)\n\nprint(\"\\n\ud83d\udcca Production Setup:\")\nprint(f\"   Train batches: {len(train_dl)}\")\nprint(f\"   Validation batches: {len(val_dl)}\")\nprint(f\"   Batch size: {train_dl.batch_size}\")\nprint(f\"   Max genes: {train_dl.max_genes}\")\n\n# Test production workflow\nprint(\"\\n\ud83e\uddea Testing production workflow:\")\n\n# Test training batch\ntrain_batch = next(iter(train_dl))\nprint(f\"   Training batch shape: {train_batch['input_ids'].shape}\")\n\n# Test validation batch\nval_batch = next(iter(val_dl))\nprint(f\"   Validation batch shape: {val_batch['input_ids'].shape}\")\n", "code_hash": "924a0e3d1ae19ee6f5dbe08ad0aa5d29", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "xXTn", "name": "_"}, {"code": "mo.md(\n    \"\"\"\n## 10. Best Practices for ML Training\n\nKey best practices for using SLAF in ML training:\n\"\"\"\n)", "code_hash": "98cb4ee253ef5535efaafb4033272c74", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "AjVT", "name": "_"}, {"code": "# Best practices for ML training\nprint(\"\ud83d\udca1 Best Practices for ML Training\")\nprint(\"=\" * 40)\n\nprint(\"1. Tokenizer Configuration:\")\nprint(\"   \u2705 Choose appropriate vocab_size based on your dataset\")\nprint(\"   \u2705 Use n_expression_bins=50 for fine-grained expression modeling\")\nprint(\"   \u2705 Set chunk_size based on available memory\")\n\nprint(\"\\n2. DataLoader Configuration:\")\nprint(\"   \u2705 Start with small batch_size and increase gradually\")\nprint(\"   \u2705 Use max_genes appropriate for your model architecture\")\nprint(\"   \u2705 Set num_workers based on CPU cores\")\n\nprint(\"\\n3. Performance Optimization:\")\nprint(\"   \u2705 Use SQL binning for scGPT tokenization\")\nprint(\"   \u2705 Leverage percentile filtering for Geneformer\")\nprint(\"   \u2705 Monitor memory usage during training\")\n\nprint(\"\\n4. Training Workflow:\")\nprint(\"   \u2705 Create separate train/val/test splits\")\nprint(\"   \u2705 Use consistent tokenizer across splits\")\nprint(\"   \u2705 Implement proper error handling\")\n\nprint(\"\\n5. Production Considerations:\")\nprint(\"   \u2705 Use appropriate batch sizes for your hardware\")\nprint(\"   \u2705 Implement checkpointing for long training runs\")\nprint(\"   \u2705 Monitor tokenization throughput\")\nprint(\"   \u2705 Consider distributed training for large datasets\")\n", "code_hash": "45b2a2e8343ea33a61d106926d669961", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "pHFh", "name": "_"}, {"code": "mo.md(\n    \"\"\"\n## Summary\n\n**What you've learned about SLAF ML Training:**\n\n1. **Tokenizer Configuration**: Customize vocabulary size, expression bins, and chunking\n2. **Tokenization Strategies**: Geneformer and scGPT formats with different performance characteristics\n3. **DataLoader Integration**: High-performance data loading with PyTorch compatibility\n4. **Performance Optimization**: SQL-level performance with memory efficiency\n5. **Custom Implementation**: How to build custom DataLoaders for specific needs\n6. **Production Workflow**: Complete training pipeline setup\n7. **Best Practices**: Guidelines for optimal ML training performance\n\"\"\"\n)", "code_hash": "14f8546b39a00f3b4dda5092c4893f60", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "NCOB", "name": "_"}, {"code": "", "code_hash": null, "config": {"column": null, "disabled": false, "hide_code": false}, "id": "aqbW", "name": "_"}], "metadata": {"marimo_version": "0.14.0"}, "version": "1"},
            "session": {"cells": [{"code_hash": "72bd3eb48288fa44e643be397d86a48d", "console": [], "id": "Hbol", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "2a896a97387b10cc623231a5dd440273", "console": [], "id": "MJUe", "outputs": [{"data": {"text/html": "<span class=\"markdown prose dark:prose-invert\"><h1 id=\"slaf-ml-training-pipeline\">SLAF ML Training Pipeline</h1>\n<span class=\"paragraph\">This notebook demonstrates how to build complete ML training pipelines with SLAF, including:</span>\n<ul>\n<li>\n<span class=\"paragraph\">Custom tokenizer configuration</span>\n</li>\n<li>\n<span class=\"paragraph\">Different tokenization strategies (scGPT, Geneformer)</span>\n</li>\n<li>\n<span class=\"paragraph\">DataLoader integration with PyTorch</span>\n</li>\n<li>\n<span class=\"paragraph\">Performance optimization techniques</span>\n</li>\n<li>\n<span class=\"paragraph\">Custom training loop examples</span>\n</li>\n</ul>\n<span class=\"paragraph\"><strong>Key Benefits for ML Training:</strong></span>\n<span class=\"paragraph\">\ud83d\ude80 <strong>Fast Tokenization</strong>: SQL-level performance for token generation</span>\n<span class=\"paragraph\">\ud83d\udcbe <strong>Memory Efficient</strong>: Stream data without loading everything into memory</span>\n<span class=\"paragraph\">\ud83d\udd04 <strong>Flexible</strong>: Support for different tokenization strategies and model architectures</span>\n<span class=\"paragraph\">\ud83e\uddec <strong>Production Ready</strong>: Built for large-scale training with proper splits and error handling</span>\n<span class=\"paragraph\">\u26a1 <strong>Optimized</strong>: SQL binning, percentile filtering, and other performance optimizations</span></span>"}, "type": "data"}]}, {"code_hash": "11e373832fc301071b83d550f10621c3", "console": [{"name": "stdout", "text": "\u2705 Loaded SLAF dataset: 2,695 cells \u00d7 1,863 genes\nSLAF Dataset\n  Shape: 2695 cells \u00d7 1863 genes\n  Format version: 0.1\n  Cell metadata columns: 9\n    n_genes, n_genes_by_counts, total_counts, leiden, batch...\n  Gene metadata columns: 12\n    gene_ids, n_cells, mt, n_cells_by_counts, mean_counts...\n  Record counts:\n    Cells: 2,695\n    Genes: 1,863\n    Expression records: computing...\n", "type": "stream"}, {"name": "stdout", "text": "    Expression records: 415,134\n  Optimizations:\n    use_integer_keys: True\n", "type": "stream"}], "id": "vblA", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "baad5c54234ca597715c5d34701b941d", "console": [], "id": "bkHC", "outputs": [{"data": {"text/html": "<span class=\"markdown prose dark:prose-invert\"><h2 id=\"1-understanding-slaf-tokenization\">1. Understanding SLAF Tokenization</h2>\n<span class=\"paragraph\">SLAF provides efficient tokenization for single-cell data, supporting multiple strategies:</span></span>"}, "type": "data"}]}, {"code_hash": "ef422617146b4f7876898bfbff2f293e", "console": [], "id": "lEQa", "outputs": [{"data": {"text/html": "<span class=\"markdown prose dark:prose-invert\"><h3 id=\"tokenizer-configuration\">Tokenizer Configuration</h3></span>"}, "type": "data"}]}, {"code_hash": "92bd590923a6d488a2f750f269058d11", "console": [{"name": "stdout", "text": "\u2705 Tokenizer initialized:\n   Total vocabulary size: 1,887\n   Special tokens: {'CLS': 0, 'SEP': 1, 'PAD': 2, 'UNK': 3}\n   Expression bins: 20\n   Gene vocabulary size: 5,000\n\nSpecial tokens:\n   CLS: 0\n   SEP: 1\n   PAD: 2\n   UNK: 3\n", "type": "stream"}], "id": "PKri", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "791464f54081db5ad49cad5e4a233b75", "console": [], "id": "Xref", "outputs": [{"data": {"text/html": "<span class=\"markdown prose dark:prose-invert\"><h2 id=\"2-tokenization-strategies\">2. Tokenization Strategies</h2>\n<span class=\"paragraph\">SLAF supports different tokenization strategies for different model architectures:</span></span>"}, "type": "data"}]}, {"code_hash": "9daede8d407089963c076ad00b9ee3a6", "console": [], "id": "SFPL", "outputs": [{"data": {"text/html": "<span class=\"markdown prose dark:prose-invert\"><h3 id=\"geneformer-and-scgpt-style-tokenization\">Geneformer and scGPT style tokenization</h3></span>"}, "type": "data"}]}, {"code_hash": "5dc85de5528ea0b16d6be8c4e3a39a91", "console": [{"name": "stdout", "text": "\n1. Geneformer Tokenization:\n   Format: [gene1, gene2, gene3, ...] (sorted by expression)\n", "type": "stream"}, {"name": "stdout", "text": "   Generated 10 sequences of length 50\n\n2. scGPT Tokenization:\n   Format: [CLS] gene1 expr1 gene2 expr2 ... [SEP]\n   Generated 10 sequences of length 52\n", "type": "stream"}], "id": "BYtC", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "8b92c64b12c42886b6c9a7181d4cec91", "console": [], "id": "RGSE", "outputs": [{"data": {"text/html": "<span class=\"markdown prose dark:prose-invert\"><h3 id=\"token-decoding-examples\">Token decoding examples</h3></span>"}, "type": "data"}]}, {"code_hash": "abb2ff5dc1d64bfa0d754c6883fbbf58", "console": [{"name": "stdout", "text": "1. Geneformer sequence decoding:\n   Sequence length: 50\n   Genes: 29 genes\n   First few genes: ['NOL7', 'CCL5', 'MT-ATP6']\n\n2. scGPT sequence decoding:\n   Sequence length: 52\n   Special tokens: ['CLS', 'SEP']\n   Genes: 25 genes\n   Expression bins: 25 bins\n   First few genes: ['NOL7', 'CCL5', 'MT-ATP6']\n   First few expression bins: [16.0, 15.0, 11.0]\n", "type": "stream"}], "id": "Kclp", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "135518d0ce6c8e15f92f65d4d88ebf31", "console": [], "id": "emfo", "outputs": [{"data": {"text/html": "<span class=\"markdown prose dark:prose-invert\"><h2 id=\"3-performance-comparison-different-tokenization-approaches\">3. Performance Comparison - Different Tokenization Approaches</h2>\n<span class=\"paragraph\">Let's compare the performance of different tokenization strategies:</span></span>"}, "type": "data"}]}, {"code_hash": "8d888c7fd6e32b90f8328bc22e2e17db", "console": [{"name": "stdout", "text": "Task completed\nElapsed time captured from context manager object: 2.0054 seconds\n", "type": "stream"}], "id": "Hstk", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "2bebd602c2886c2ca5bf541f3b9e8cf9", "console": [{"name": "stdout", "text": "\u26a1 Tokenization Performance Comparison\n=============================================\n\n1. Geneformer Performance:\n", "type": "stream"}, {"name": "stdout", "text": "    Geneformer [standard]: 0.0234s\n   Geneformer [percentile]: 0.0143s\n   Speedup: 1.64x\n\n2. scGPT Performance:\n", "type": "stream"}, {"name": "stdout", "text": "   scGPT [Python]: 0.0140s\n   scGPT [SQL]: 0.0127s\n   Speedup: 1.11x\n\n3. Throughput:\n   Geneformer [standard]: 426,551 tokens/sec\n   Geneformer [percentile]: 698,188 tokens/sec\n   scGPT [Python]: 728,862 tokens/sec\n   scGPT [SQL]: 806,239 tokens/sec\n", "type": "stream"}], "id": "nWHF", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "50f70483b9ee433c38f0251d5dc6e8e7", "console": [], "id": "iLit", "outputs": [{"data": {"text/html": "<span class=\"markdown prose dark:prose-invert\"><h2 id=\"4-slaf-dataloader-production-ready-training\">4. SLAF DataLoader - Production-Ready Training</h2>\n<span class=\"paragraph\">SLAF provides a high-performance DataLoader for training:</span></span>"}, "type": "data"}]}, {"code_hash": "0aa79ddc456736912c954453423d901c", "console": [{"name": "stdout", "text": "\ud83d\udce6 SLAF DataLoader Configuration\n========================================\n\u2705 DataLoader initialized:\n   Tokenizer type: geneformer\n   Batch size: 16\n   Max genes: 100\n   Number of batches: 169\n   Special tokens: {'CLS': 0, 'SEP': 1, 'PAD': 2, 'UNK': 3}\n", "type": "stream"}], "id": "ZHCJ", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "938b9ca6b14553bd608d5e14ae57bceb", "console": [{"name": "stdout", "text": "\ud83d\udd04 DataLoader Iteration\n=========================\n1. First batch structure:\n", "type": "stream"}, {"name": "stdout", "text": "   input_ids: <class 'torch.Tensor'> with shape torch.Size([16, 100])\n   attention_mask: <class 'torch.Tensor'> with shape torch.Size([16, 100])\n   cell_ids: <class 'torch.Tensor'> with shape torch.Size([16])\n\n2. Batch details:\n   Input IDs shape: torch.Size([16, 100])\n   Attention mask shape: torch.Size([16, 100])\n   Cell IDs shape: torch.Size([16])\n   Data type: torch.int64\n\n3. Sample tokens from first sequence:\n   First 10 tokens: [600, 1520, 1885, 1277, 618, 164, 1302, 665, 509, 743]\n   Sequence length: 100\n", "type": "stream"}], "id": "ROlb", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "e947ddb4d19a29ecef9e2ffb10c3ee27", "console": [{"name": "stdout", "text": "\u26a1 DataLoader Performance\n==============================\n1. Iteration performance:\n", "type": "stream"}, {"name": "stdout", "text": "   Processed 5 batches in 0.0312s\n   Total tokens: 8,000\n   Tokens per second: 256,531\n   Batches per second: 160.33\n", "type": "stream"}], "id": "qnkX", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "974e2b150b9e598622d517545e946b26", "console": [], "id": "TqIu", "outputs": [{"data": {"text/html": "<span class=\"markdown prose dark:prose-invert\"><h2 id=\"5-pytorch-training-loop-integration\">5. PyTorch Training Loop Integration</h2>\n<span class=\"paragraph\">Here's how to integrate SLAF DataLoader with PyTorch training:</span></span>"}, "type": "data"}]}, {"code_hash": "7f57a87999880983a2e1f21b81b31f62", "console": [{"name": "stdout", "text": "\ud83d\udd25 PyTorch Training Loop Integration\n=============================================\n\u2705 PyTorch is available\n\n1. PyTorch tensor conversion:\n   Device info: {'torch_available': True, 'cuda_available': False, 'mps_available': True, 'optimal_device': 'mps'}\n   Using device: mps\n", "type": "stream"}, {"name": "stderr", "text": "/var/folders/4g/t2xnyv255vd8pmccptg62wq80000gn/T/marimo_19437/__marimo__cell_Vxnm_.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  input_ids_tensor = torch.tensor(\n/var/folders/4g/t2xnyv255vd8pmccptg62wq80000gn/T/marimo_19437/__marimo__cell_Vxnm_.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  attention_mask_tensor = torch.tensor(\n", "type": "stream"}, {"name": "stderr", "text": "/var/folders/4g/t2xnyv255vd8pmccptg62wq80000gn/T/marimo_19437/__marimo__cell_Vxnm_.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  cell_ids_tensor = torch.tensor(\n", "type": "stream"}, {"name": "stdout", "text": "   Input IDs tensor: torch.Size([16, 100]), torch.int64\n   Attention mask tensor: torch.Size([16, 100]), torch.bool\n   Cell IDs tensor: torch.Size([16]), torch.int64\n\n2. Simple training loop structure:\n\n        # Training loop example with smart device detection\n        from slaf.ml.dataloaders import get_optimal_device\n\n        device = get_optimal_device()\n        model = YourModel(vocab_size=tokenizer.get_vocab_info()['total_vocab_size'])\n        model = model.to(device)  # Move model to optimal device\n        optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n\n        for epoch in range(num_epochs):\n            model.train()\n            for batch in dataloader:\n                # DataLoader already provides tensors on optimal device\n                input_ids = batch[\"input_ids\"]  # Already on device\n                attention_mask = batch[\"attention_mask\"]  # Already on device\n\n                # Forward pass\n                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n                loss = outputs.loss\n\n                # Backward pass\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n        \n", "type": "stream"}], "id": "Vxnm", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "23b837624558d53057d2ef4e4ae9d63f", "console": [], "id": "DnEU", "outputs": [{"data": {"text/html": "<span class=\"markdown prose dark:prose-invert\"><h2 id=\"6-custom-dataloader-implementation\">6. Custom DataLoader Implementation</h2>\n<span class=\"paragraph\">Learn how to create custom DataLoaders for specific use cases:</span></span>"}, "type": "data"}]}, {"code_hash": "97177f0678804cb6731b2245019f4646", "console": [{"name": "stdout", "text": "\ud83d\udd27 Custom DataLoader Implementation\n========================================\n\u2705 Custom DataLoader created\n   Number of batches: 337\n   First batch shape: (8, 50)\n", "type": "stream"}], "id": "ulZA", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "386d06b7004b213dcdae8da48515cc39", "console": [], "id": "ecfG", "outputs": [{"data": {"text/html": "<span class=\"markdown prose dark:prose-invert\"><h2 id=\"7-advanced-tokenization-features\">7. Advanced Tokenization Features</h2>\n<span class=\"paragraph\">Explore advanced tokenization features and optimizations:</span></span>"}, "type": "data"}]}, {"code_hash": "dca66eb285875acfc59a47cbc6584cb1", "console": [{"name": "stdout", "text": "\ud83d\ude80 Advanced Tokenization Features\n========================================\n1. Different max_genes settings:\n", "type": "stream"}, {"name": "stdout", "text": "   max_genes=25: avg_length=25.0\n   max_genes=50: avg_length=50.0\n   max_genes=100: avg_length=100.0\n\n2. Different percentile filtering:\n", "type": "stream"}, {"name": "stdout", "text": "   min_percentile=None: avg_length=50.0\n   min_percentile=5: avg_length=50.0\n   min_percentile=10: avg_length=50.0\n", "type": "stream"}, {"name": "stdout", "text": "   min_percentile=20: avg_length=50.0\n\n3. SQL vs Python binning for scGPT:\n   SQL binning: 0.0049s\n   Python binning: 0.0045s\n   Speedup: 0.93x\n", "type": "stream"}], "id": "Pvdt", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "1b959440c168991765eb13f6be153e02", "console": [], "id": "ZBYS", "outputs": [{"data": {"text/html": "<span class=\"markdown prose dark:prose-invert\"><h2 id=\"8-memory-and-performance-optimization\">8. Memory and Performance Optimization</h2>\n<span class=\"paragraph\">Learn how to optimize memory usage and performance for large-scale training:</span></span>"}, "type": "data"}]}, {"code_hash": "e0804bfd0beaaddba7f80b3c86d39fa7", "console": [{"name": "stdout", "text": "\ud83d\udcbe Memory and Performance Optimization\n=============================================\n1. Memory usage comparison:\n   Baseline memory: 554.4 MB\n", "type": "stream"}, {"name": "stdout", "text": "   Batch size 8: 555.0 MB (+0.6 MB)\n   Batch size 16: 555.5 MB (+0.5 MB)\n", "type": "stream"}, {"name": "stdout", "text": "   Batch size 32: 557.2 MB (+1.8 MB)\n\n2. Performance with different settings:\n", "type": "stream"}, {"name": "stdout", "text": "   Small batches: 0.0157s for 3 batches\n", "type": "stream"}, {"name": "stdout", "text": "   Medium batches: 0.0166s for 3 batches\n", "type": "stream"}, {"name": "stdout", "text": "   Large batches: 0.0241s for 3 batches\n", "type": "stream"}], "id": "aLJB", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "8258f9bc568b2c9517ec0f036e28adba", "console": [], "id": "nHfw", "outputs": [{"data": {"text/html": "<span class=\"markdown prose dark:prose-invert\"><h2 id=\"9-production-training-workflow\">9. Production Training Workflow</h2>\n<span class=\"paragraph\">Complete example of a production-ready training workflow:</span></span>"}, "type": "data"}]}, {"code_hash": "924a0e3d1ae19ee6f5dbe08ad0aa5d29", "console": [{"name": "stdout", "text": "\ud83c\udfed Production Training Workflow\n========================================\n\u2705 Created tokenizer with 1917 total tokens\n\n\ud83d\udcca Production Setup:\n   Train batches: 85\n   Validation batches: 85\n   Batch size: 32\n   Max genes: 512\n\n\ud83e\uddea Testing production workflow:\n   Training batch shape: torch.Size([32, 512])\n", "type": "stream"}, {"name": "stdout", "text": "   Validation batch shape: torch.Size([32, 512])\n", "type": "stream"}], "id": "xXTn", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "98cb4ee253ef5535efaafb4033272c74", "console": [], "id": "AjVT", "outputs": [{"data": {"text/html": "<span class=\"markdown prose dark:prose-invert\"><h2 id=\"10-best-practices-for-ml-training\">10. Best Practices for ML Training</h2>\n<span class=\"paragraph\">Key best practices for using SLAF in ML training:</span></span>"}, "type": "data"}]}, {"code_hash": "45b2a2e8343ea33a61d106926d669961", "console": [{"name": "stdout", "text": "\ud83d\udca1 Best Practices for ML Training\n========================================\n1. Tokenizer Configuration:\n   \u2705 Choose appropriate vocab_size based on your dataset\n   \u2705 Use n_expression_bins=50 for fine-grained expression modeling\n   \u2705 Set chunk_size based on available memory\n\n2. DataLoader Configuration:\n   \u2705 Start with small batch_size and increase gradually\n   \u2705 Use max_genes appropriate for your model architecture\n   \u2705 Set num_workers based on CPU cores\n\n3. Performance Optimization:\n   \u2705 Use SQL binning for scGPT tokenization\n   \u2705 Leverage percentile filtering for Geneformer\n   \u2705 Monitor memory usage during training\n\n4. Training Workflow:\n   \u2705 Create separate train/val/test splits\n   \u2705 Use consistent tokenizer across splits\n   \u2705 Implement proper error handling\n\n5. Production Considerations:\n   \u2705 Use appropriate batch sizes for your hardware\n   \u2705 Implement checkpointing for long training runs\n   \u2705 Monitor tokenization throughput\n   \u2705 Consider distributed training for large datasets\n", "type": "stream"}], "id": "pHFh", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "14f8546b39a00f3b4dda5092c4893f60", "console": [], "id": "NCOB", "outputs": [{"data": {"text/html": "<span class=\"markdown prose dark:prose-invert\"><h2 id=\"summary\">Summary</h2>\n<span class=\"paragraph\"><strong>What you've learned about SLAF ML Training:</strong></span>\n<ol>\n<li><strong>Tokenizer Configuration</strong>: Customize vocabulary size, expression bins, and chunking</li>\n<li><strong>Tokenization Strategies</strong>: Geneformer and scGPT formats with different performance characteristics</li>\n<li><strong>DataLoader Integration</strong>: High-performance data loading with PyTorch compatibility</li>\n<li><strong>Performance Optimization</strong>: SQL-level performance with memory efficiency</li>\n<li><strong>Custom Implementation</strong>: How to build custom DataLoaders for specific needs</li>\n<li><strong>Production Workflow</strong>: Complete training pipeline setup</li>\n<li><strong>Best Practices</strong>: Guidelines for optimal ML training performance</li>\n</ol></span>"}, "type": "data"}]}, {"code_hash": null, "console": [], "id": "aqbW", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}], "metadata": {"marimo_version": "0.14.0"}, "version": "1"},
            "runtimeConfig": null,
        };
    </script>

<marimo-code hidden="">
    import%20marimo%0A%0A__generated_with%20%3D%20%220.14.0%22%0Aapp%20%3D%20marimo.App(width%3D%22medium%22)%0A%0A%0A%40app.cell%0Adef%20_()%3A%0A%20%20%20%20import%20time%0A%0A%20%20%20%20import%20marimo%20as%20mo%0A%20%20%20%20import%20numpy%20as%20np%0A%0A%20%20%20%20from%20slaf%20import%20SLAFArray%0A%20%20%20%20from%20slaf.ml.dataloaders%20import%20SLAFDataLoader%0A%20%20%20%20from%20slaf.ml.tokenizers%20import%20SLAFTokenizer%0A%0A%20%20%20%20return%20SLAFArray%2C%20SLAFDataLoader%2C%20SLAFTokenizer%2C%20mo%2C%20np%2C%20time%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(%0A%20%20%20%20%20%20%20%20%22%22%22%0A%20%20%20%20%23%20SLAF%20ML%20Training%20Pipeline%0A%0A%20%20%20%20This%20notebook%20demonstrates%20how%20to%20build%20complete%20ML%20training%20pipelines%20with%20SLAF%2C%20including%3A%0A%0A%20%20%20%20-%20Custom%20tokenizer%20configuration%0A%0A%20%20%20%20-%20Different%20tokenization%20strategies%20(scGPT%2C%20Geneformer)%0A%0A%20%20%20%20-%20DataLoader%20integration%20with%20PyTorch%0A%0A%20%20%20%20-%20Performance%20optimization%20techniques%0A%0A%20%20%20%20-%20Custom%20training%20loop%20examples%0A%0A%20%20%20%20**Key%20Benefits%20for%20ML%20Training%3A**%0A%0A%20%20%20%20%F0%9F%9A%80%20**Fast%20Tokenization**%3A%20SQL-level%20performance%20for%20token%20generation%0A%0A%20%20%20%20%F0%9F%92%BE%20**Memory%20Efficient**%3A%20Stream%20data%20without%20loading%20everything%20into%20memory%0A%0A%20%20%20%20%F0%9F%94%84%20**Flexible**%3A%20Support%20for%20different%20tokenization%20strategies%20and%20model%20architectures%0A%0A%20%20%20%20%F0%9F%A7%AC%20**Production%20Ready**%3A%20Built%20for%20large-scale%20training%20with%20proper%20splits%20and%20error%20handling%0A%0A%20%20%20%20%E2%9A%A1%20**Optimized**%3A%20SQL%20binning%2C%20percentile%20filtering%2C%20and%20other%20performance%20optimizations%0A%20%20%20%20%22%22%22%0A%20%20%20%20)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(SLAFArray)%3A%0A%20%20%20%20%23%20Load%20SLAF%20dataset%20for%20ML%20examples%0A%20%20%20%20slaf%20%3D%20SLAFArray(%22..%2Fslaf-datasets%2Fpbmc3k_processed.slaf%22)%0A%20%20%20%20print(f%22%E2%9C%85%20Loaded%20SLAF%20dataset%3A%20%7Bslaf.shape%5B0%5D%3A%2C%7D%20cells%20%C3%97%20%7Bslaf.shape%5B1%5D%3A%2C%7D%20genes%22)%0A%0A%20%20%20%20%23%20Show%20dataset%20info%0A%20%20%20%20slaf.info()%0A%20%20%20%20return%20(slaf%2C)%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(%0A%20%20%20%20%20%20%20%20%22%22%22%0A%20%20%20%20%23%23%201.%20Understanding%20SLAF%20Tokenization%0A%0A%20%20%20%20SLAF%20provides%20efficient%20tokenization%20for%20single-cell%20data%2C%20supporting%20multiple%20strategies%3A%0A%20%20%20%20%22%22%22%0A%20%20%20%20)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%23%23%23%20Tokenizer%20Configuration%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(SLAFTokenizer%2C%20slaf)%3A%0A%20%20%20%20%23%20Create%20tokenizer%20with%20custom%20settings%0A%20%20%20%20tokenizer%20%3D%20SLAFTokenizer(%0A%20%20%20%20%20%20%20%20slaf_array%3Dslaf%2C%0A%20%20%20%20%20%20%20%20vocab_size%3D5000%2C%20%20%23%20Smaller%20vocab%20for%20demo%0A%20%20%20%20%20%20%20%20n_expression_bins%3D20%2C%20%20%23%20More%20expression%20bins%0A%20%20%20%20%20%20%20%20chunk_size%3D512%2C%20%20%23%20Smaller%20chunks%20for%20memory%20efficiency%0A%20%20%20%20)%0A%0A%20%20%20%20%23%20Get%20vocabulary%20information%0A%20%20%20%20vocab_info%20%3D%20tokenizer.get_vocab_info()%0A%20%20%20%20print(%22%E2%9C%85%20Tokenizer%20initialized%3A%22)%0A%20%20%20%20print(f%22%20%20%20Total%20vocabulary%20size%3A%20%7Bvocab_info%5B'total_vocab_size'%5D%3A%2C%7D%22)%0A%20%20%20%20print(f%22%20%20%20Special%20tokens%3A%20%7Bvocab_info%5B'special_tokens'%5D%7D%22)%0A%20%20%20%20print(f%22%20%20%20Expression%20bins%3A%20%7Bvocab_info%5B'n_expression_bins'%5D%7D%22)%0A%20%20%20%20print(f%22%20%20%20Gene%20vocabulary%20size%3A%20%7Bvocab_info%5B'vocab_size'%5D%3A%2C%7D%22)%0A%0A%20%20%20%20%23%20Show%20special%20tokens%0A%20%20%20%20print(%22%5CnSpecial%20tokens%3A%22)%0A%20%20%20%20for%20token_name%2C%20token_id%20in%20tokenizer.special_tokens.items()%3A%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20%7Btoken_name%7D%3A%20%7Btoken_id%7D%22)%0A%0A%20%20%20%20return%20(tokenizer%2C)%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(%0A%20%20%20%20%20%20%20%20%22%22%22%0A%20%20%20%20%23%23%202.%20Tokenization%20Strategies%0A%0A%20%20%20%20SLAF%20supports%20different%20tokenization%20strategies%20for%20different%20model%20architectures%3A%0A%20%20%20%20%22%22%22%0A%20%20%20%20)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%23%23%23%20Geneformer%20and%20scGPT%20style%20tokenization%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(tokenizer)%3A%0A%20%20%20%20%23%20Tokenize%20a%20small%20batch%20of%20cells%20for%20demonstration%0A%0A%20%20%20%20%23%201.%20Geneformer%20tokenization%0A%20%20%20%20print(%22%5Cn1.%20Geneformer%20Tokenization%3A%22)%0A%20%20%20%20print(%22%20%20%20Format%3A%20%5Bgene1%2C%20gene2%2C%20gene3%2C%20...%5D%20(sorted%20by%20expression)%22)%0A%0A%20%20%20%20geneformer_tokens%20%3D%20tokenizer.tokenize_geneformer(%0A%20%20%20%20%20%20%20%20cell_integer_id_range%3D(0%2C%2010)%2C%20%20%23%20Limit%20for%20demo%0A%20%20%20%20%20%20%20%20max_genes%3D50%2C%20%20%23%20Limit%20for%20demo%0A%20%20%20%20%20%20%20%20min_percentile%3D10%2C%20%20%23%20Filter%20low-expression%20genes%0A%20%20%20%20)%0A%0A%20%20%20%20print(%0A%20%20%20%20%20%20%20%20f%22%20%20%20Generated%20%7Blen(geneformer_tokens)%7D%20sequences%20of%20length%20%7Blen(geneformer_tokens%5B0%5D)%7D%22%0A%20%20%20%20)%0A%0A%20%20%20%20%23%202.%20scGPT%20tokenization%0A%20%20%20%20print(%22%5Cn2.%20scGPT%20Tokenization%3A%22)%0A%20%20%20%20print(%22%20%20%20Format%3A%20%5BCLS%5D%20gene1%20expr1%20gene2%20expr2%20...%20%5BSEP%5D%22)%0A%0A%20%20%20%20scgpt_tokens%20%3D%20tokenizer.tokenize_scgpt(%0A%20%20%20%20%20%20%20%20cell_integer_id_range%3D(0%2C%2010)%2C%20%20%23%20Limit%20for%20demo%20(scGPT%20sequences%20are%20longer)%0A%20%20%20%20%20%20%20%20max_genes%3D25%2C%20%20%23%20Limit%20for%20demo%20(scGPT%20sequences%20are%20longer)%0A%20%20%20%20%20%20%20%20use_sql_binning%3DTrue%2C%20%20%23%20Use%20SQL%20for%20better%20performance%0A%20%20%20%20)%0A%0A%20%20%20%20print(%0A%20%20%20%20%20%20%20%20f%22%20%20%20Generated%20%7Blen(scgpt_tokens)%7D%20sequences%20of%20length%20%7Blen(scgpt_tokens%5B0%5D)%7D%22%0A%20%20%20%20)%0A%0A%20%20%20%20return%20geneformer_tokens%2C%20scgpt_tokens%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%23%23%23%20Token%20decoding%20examples%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(geneformer_tokens%2C%20scgpt_tokens%2C%20tokenizer)%3A%0A%20%20%20%20%23%20Demonstrate%20token%20decoding%0A%20%20%20%20if%20geneformer_tokens%3A%0A%20%20%20%20%20%20%20%20print(%221.%20Geneformer%20sequence%20decoding%3A%22)%0A%20%20%20%20%20%20%20%20decoded_geneformer%20%3D%20tokenizer.decode_tokens(geneformer_tokens%5B0%5D)%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20Sequence%20length%3A%20%7Blen(geneformer_tokens%5B0%5D)%7D%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20Genes%3A%20%7Blen(decoded_geneformer%5B'genes'%5D)%7D%20genes%22)%0A%20%20%20%20%20%20%20%20if%20decoded_geneformer%5B%22genes%22%5D%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%20%20%20First%20few%20genes%3A%20%7Bdecoded_geneformer%5B'genes'%5D%5B%3A3%5D%7D%22)%0A%0A%20%20%20%20if%20scgpt_tokens%3A%0A%20%20%20%20%20%20%20%20print(%22%5Cn2.%20scGPT%20sequence%20decoding%3A%22)%0A%20%20%20%20%20%20%20%20decoded_scgpt%20%3D%20tokenizer.decode_tokens(scgpt_tokens%5B0%5D)%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20Sequence%20length%3A%20%7Blen(scgpt_tokens%5B0%5D)%7D%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20Special%20tokens%3A%20%7Bdecoded_scgpt%5B'special_tokens'%5D%7D%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20Genes%3A%20%7Blen(decoded_scgpt%5B'genes'%5D)%7D%20genes%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20Expression%20bins%3A%20%7Blen(decoded_scgpt%5B'expression_bins'%5D)%7D%20bins%22)%0A%20%20%20%20%20%20%20%20if%20decoded_scgpt%5B%22genes%22%5D%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%20%20%20First%20few%20genes%3A%20%7Bdecoded_scgpt%5B'genes'%5D%5B%3A3%5D%7D%22)%0A%20%20%20%20%20%20%20%20%20%20%20%20print(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20f%22%20%20%20First%20few%20expression%20bins%3A%20%7Bdecoded_scgpt%5B'expression_bins'%5D%5B%3A3%5D%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(%0A%20%20%20%20%20%20%20%20%22%22%22%0A%20%20%20%20%23%23%203.%20Performance%20Comparison%20-%20Different%20Tokenization%20Approaches%0A%0A%20%20%20%20Let's%20compare%20the%20performance%20of%20different%20tokenization%20strategies%3A%0A%20%20%20%20%22%22%22%0A%20%20%20%20)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(time)%3A%0A%20%20%20%20class%20Timer%3A%0A%20%20%20%20%20%20%20%20def%20__init__(self%2C%20name%3DNone)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20self.name%20%3D%20name%0A%20%20%20%20%20%20%20%20%20%20%20%20self.elapsed%20%3D%200.0%0A%20%20%20%20%20%20%20%20%20%20%20%20self._start_time%20%3D%20None%0A%0A%20%20%20%20%20%20%20%20def%20__enter__(self)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20self._start_time%20%3D%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20time.perf_counter()%0A%20%20%20%20%20%20%20%20%20%20%20%20)%20%20%23%20Use%20perf_counter%20for%20more%20accurate%20timing%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20self%0A%0A%20%20%20%20%20%20%20%20def%20__exit__(self%2C%20exc_type%2C%20exc_val%2C%20exc_tb)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20if%20self._start_time%20is%20not%20None%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20end_time%20%3D%20time.perf_counter()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.elapsed%20%3D%20end_time%20-%20self._start_time%0A%0A%20%20%20%20%23%20Usage%0A%20%20%20%20with%20Timer(%22My%20Task%22)%20as%20t%3A%0A%20%20%20%20%20%20%20%20%23%20Code%20to%20be%20timed%0A%20%20%20%20%20%20%20%20time.sleep(2)%20%20%23%20Simulate%20some%20work%0A%20%20%20%20%20%20%20%20print(%22Task%20completed%22)%0A%0A%20%20%20%20print(f%22Elapsed%20time%20captured%20from%20context%20manager%20object%3A%20%7Bt.elapsed%3A.4f%7D%20seconds%22)%0A%0A%20%20%20%20return%20(Timer%2C)%0A%0A%0A%40app.cell%0Adef%20_(Timer%2C%20tokenizer)%3A%0A%20%20%20%20%23%20Performance%20comparison%0A%20%20%20%20print(%22%E2%9A%A1%20Tokenization%20Performance%20Comparison%22)%0A%20%20%20%20print(%22%3D%22%20*%2045)%0A%0A%20%20%20%20def%20demo_tokenizer_performance()%3A%0A%20%20%20%20%20%20%20%20%23%20Test%20Geneformer%20with%20100%20cells%0A%20%20%20%20%20%20%20%20print(%22%5Cn1.%20Geneformer%20Performance%3A%22)%0A%0A%20%20%20%20%20%20%20%20%23%20Standard%20Geneformer%0A%20%20%20%20%20%20%20%20with%20Timer(%22geneformer_standard%22)%20as%20standard_time%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20geneformer_standard%20%3D%20tokenizer.tokenize_geneformer(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20(0%2C%20100)%2C%20max_genes%3D100%2C%20min_percentile%3DNone%0A%20%20%20%20%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20%20Geneformer%20%5Bstandard%5D%3A%20%7Bstandard_time.elapsed%3A.4f%7Ds%22)%0A%20%20%20%20%20%20%20%20%23%20Geneformer%20with%20percentile%20filtering%0A%20%20%20%20%20%20%20%20with%20Timer(%22geneformer_percentile%22)%20as%20percentile_time%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20_%20%3D%20tokenizer.tokenize_geneformer(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20(0%2C%20100)%2C%20max_genes%3D100%2C%20min_percentile%3D10%0A%20%20%20%20%20%20%20%20%20%20%20%20)%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20Geneformer%20%5Bpercentile%5D%3A%20%7Bpercentile_time.elapsed%3A.4f%7Ds%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20Speedup%3A%20%7Bstandard_time.elapsed%20%2F%20percentile_time.elapsed%3A.2f%7Dx%22)%0A%0A%20%20%20%20%20%20%20%20%23%20Test%20scGPT%20with%20different%20settings%0A%20%20%20%20%20%20%20%20print(%22%5Cn2.%20scGPT%20Performance%3A%22)%0A%0A%20%20%20%20%20%20%20%20%23%20scGPT%20with%20Python%20binning%0A%20%20%20%20%20%20%20%20with%20Timer(%22scgpt_python%22)%20as%20python_time%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20_%20%3D%20tokenizer.tokenize_scgpt((0%2C%20100)%2C%20max_genes%3D50%2C%20use_sql_binning%3DFalse)%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20scGPT%20%5BPython%5D%3A%20%7Bpython_time.elapsed%3A.4f%7Ds%22)%0A%0A%20%20%20%20%20%20%20%20%23%20scGPT%20with%20SQL%20binning%0A%20%20%20%20%20%20%20%20with%20Timer(%22scgpt_sql%22)%20as%20sql_time%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20scgpt_sql%20%3D%20tokenizer.tokenize_scgpt(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20(0%2C%20100)%2C%20max_genes%3D50%2C%20use_sql_binning%3DTrue%0A%20%20%20%20%20%20%20%20%20%20%20%20)%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20scGPT%20%5BSQL%5D%3A%20%7Bsql_time.elapsed%3A.4f%7Ds%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20Speedup%3A%20%7Bpython_time.elapsed%20%2F%20sql_time.elapsed%3A.2f%7Dx%22)%0A%0A%20%20%20%20%20%20%20%20%23%20Calculate%20tokens%20per%20second%0A%20%20%20%20%20%20%20%20total_tokens_geneformer%20%3D%20sum(len(seq)%20for%20seq%20in%20geneformer_standard)%0A%20%20%20%20%20%20%20%20total_tokens_scgpt%20%3D%20sum(len(seq)%20for%20seq%20in%20scgpt_sql)%0A%0A%20%20%20%20%20%20%20%20print(%22%5Cn3.%20Throughput%3A%22)%0A%20%20%20%20%20%20%20%20print(%0A%20%20%20%20%20%20%20%20%20%20%20%20f%22%20%20%20Geneformer%20%5Bstandard%5D%3A%20%7Btotal_tokens_geneformer%20%2F%20standard_time.elapsed%3A%2C.0f%7D%20tokens%2Fsec%22%0A%20%20%20%20%20%20%20%20)%0A%20%20%20%20%20%20%20%20print(%0A%20%20%20%20%20%20%20%20%20%20%20%20f%22%20%20%20Geneformer%20%5Bpercentile%5D%3A%20%7Btotal_tokens_geneformer%20%2F%20percentile_time.elapsed%3A%2C.0f%7D%20tokens%2Fsec%22%0A%20%20%20%20%20%20%20%20)%0A%20%20%20%20%20%20%20%20print(%0A%20%20%20%20%20%20%20%20%20%20%20%20f%22%20%20%20scGPT%20%5BPython%5D%3A%20%7Btotal_tokens_scgpt%20%2F%20python_time.elapsed%3A%2C.0f%7D%20tokens%2Fsec%22%0A%20%20%20%20%20%20%20%20)%0A%20%20%20%20%20%20%20%20print(%0A%20%20%20%20%20%20%20%20%20%20%20%20f%22%20%20%20scGPT%20%5BSQL%5D%3A%20%7Btotal_tokens_scgpt%20%2F%20sql_time.elapsed%3A%2C.0f%7D%20tokens%2Fsec%22%0A%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20demo_tokenizer_performance()%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(%0A%20%20%20%20%20%20%20%20%22%22%22%0A%20%20%20%20%23%23%204.%20SLAF%20DataLoader%20-%20Production-Ready%20Training%0A%0A%20%20%20%20SLAF%20provides%20a%20high-performance%20DataLoader%20for%20training%3A%0A%20%20%20%20%22%22%22%0A%20%20%20%20)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(SLAFDataLoader%2C%20slaf)%3A%0A%20%20%20%20%23%20Initialize%20DataLoader%0A%20%20%20%20print(%22%F0%9F%93%A6%20SLAF%20DataLoader%20Configuration%22)%0A%20%20%20%20print(%22%3D%22%20*%2040)%0A%0A%20%20%20%20%23%20Create%20DataLoader%20with%20custom%20settings%0A%20%20%20%20dataloader%20%3D%20SLAFDataLoader(%0A%20%20%20%20%20%20%20%20slaf_array%3Dslaf%2C%0A%20%20%20%20%20%20%20%20tokenizer_type%3D%22geneformer%22%2C%20%20%23%20or%20%22scgpt%22%0A%20%20%20%20%20%20%20%20batch_size%3D16%2C%20%20%23%20Small%20batch%20for%20demo%0A%20%20%20%20%20%20%20%20max_genes%3D100%2C%0A%20%20%20%20%20%20%20%20num_workers%3D2%2C%20%20%23%20Number%20of%20worker%20processes%0A%20%20%20%20%20%20%20%20vocab_size%3D5000%2C%0A%20%20%20%20%20%20%20%20n_expression_bins%3D20%2C%0A%20%20%20%20%20%20%20%20chunk_size%3D512%2C%0A%20%20%20%20)%0A%0A%20%20%20%20print(%22%E2%9C%85%20DataLoader%20initialized%3A%22)%0A%20%20%20%20print(f%22%20%20%20Tokenizer%20type%3A%20%7Bdataloader.tokenizer_type%7D%22)%0A%20%20%20%20print(f%22%20%20%20Batch%20size%3A%20%7Bdataloader.batch_size%7D%22)%0A%20%20%20%20print(f%22%20%20%20Max%20genes%3A%20%7Bdataloader.max_genes%7D%22)%0A%20%20%20%20print(f%22%20%20%20Number%20of%20batches%3A%20%7Blen(dataloader)%7D%22)%0A%20%20%20%20print(f%22%20%20%20Special%20tokens%3A%20%7Bdataloader.special_tokens%7D%22)%0A%0A%20%20%20%20return%20(dataloader%2C)%0A%0A%0A%40app.cell%0Adef%20_(dataloader)%3A%0A%20%20%20%20%23%20Demonstrate%20DataLoader%20iteration%0A%20%20%20%20print(%22%F0%9F%94%84%20DataLoader%20Iteration%22)%0A%20%20%20%20print(%22%3D%22%20*%2025)%0A%0A%20%20%20%20def%20demo_dataloader_iteration(dataloader)%3A%0A%20%20%20%20%20%20%20%20%23%20Get%20first%20batch%0A%20%20%20%20%20%20%20%20print(%221.%20First%20batch%20structure%3A%22)%0A%20%20%20%20%20%20%20%20batch%20%3D%20next(iter(dataloader))%0A%0A%20%20%20%20%20%20%20%20for%20key%2C%20value%20in%20batch.items()%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20if%20hasattr(value%2C%20%22shape%22)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%20%20%20%7Bkey%7D%3A%20%7Btype(value)%7D%20with%20shape%20%7Bvalue.shape%7D%22)%0A%20%20%20%20%20%20%20%20%20%20%20%20else%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%20%20%20%7Bkey%7D%3A%20%7Btype(value)%7D%20with%20length%20%7Blen(value)%7D%22)%0A%0A%20%20%20%20%20%20%20%20%23%20Show%20batch%20details%0A%20%20%20%20%20%20%20%20input_ids%20%3D%20batch%5B%22input_ids%22%5D%0A%20%20%20%20%20%20%20%20attention_mask%20%3D%20batch%5B%22attention_mask%22%5D%0A%20%20%20%20%20%20%20%20cell_ids%20%3D%20batch%5B%22cell_ids%22%5D%0A%0A%20%20%20%20%20%20%20%20print(%22%5Cn2.%20Batch%20details%3A%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20Input%20IDs%20shape%3A%20%7Binput_ids.shape%7D%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20Attention%20mask%20shape%3A%20%7Battention_mask.shape%7D%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20Cell%20IDs%20shape%3A%20%7Bcell_ids.shape%7D%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20Data%20type%3A%20%7Binput_ids.dtype%7D%22)%0A%0A%20%20%20%20%20%20%20%20%23%20Show%20sample%20tokens%0A%20%20%20%20%20%20%20%20print(%22%5Cn3.%20Sample%20tokens%20from%20first%20sequence%3A%22)%0A%20%20%20%20%20%20%20%20first_seq%20%3D%20input_ids%5B0%5D%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20First%2010%20tokens%3A%20%7Bfirst_seq%5B%3A10%5D.tolist()%7D%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20Sequence%20length%3A%20%7Blen(first_seq)%7D%22)%0A%0A%20%20%20%20demo_dataloader_iteration(dataloader)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(Timer%2C%20dataloader)%3A%0A%20%20%20%20%23%20Performance%20testing%20of%20DataLoader%0A%20%20%20%20print(%22%E2%9A%A1%20DataLoader%20Performance%22)%0A%20%20%20%20print(%22%3D%22%20*%2030)%0A%0A%20%20%20%20%23%20Test%20iteration%20speed%0A%20%20%20%20print(%221.%20Iteration%20performance%3A%22)%0A%0A%20%20%20%20def%20demo_dataloader_iteration_performance()%3A%0A%20%20%20%20%20%20%20%20batch_count%20%3D%200%0A%20%20%20%20%20%20%20%20total_tokens%20%3D%200%0A%0A%20%20%20%20%20%20%20%20for%20batch%20in%20dataloader%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20batch_count%20%2B%3D%201%0A%20%20%20%20%20%20%20%20%20%20%20%20total_tokens%20%2B%3D%20batch%5B%22input_ids%22%5D.shape%5B0%5D%20*%20batch%5B%22input_ids%22%5D.shape%5B1%5D%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Only%20process%20first%20few%20batches%20for%20demo%0A%20%20%20%20%20%20%20%20%20%20%20%20if%20batch_count%20%3E%3D%205%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20break%0A%20%20%20%20%20%20%20%20return%20batch_count%2C%20total_tokens%0A%0A%20%20%20%20with%20Timer(%22dataloader_iteration%22)%20as%20iteration_time%3A%0A%20%20%20%20%20%20%20%20batch_count%2C%20total_tokens%20%3D%20demo_dataloader_iteration_performance()%0A%0A%20%20%20%20print(f%22%20%20%20Processed%20%7Bbatch_count%7D%20batches%20in%20%7Biteration_time.elapsed%3A.4f%7Ds%22)%0A%20%20%20%20print(f%22%20%20%20Total%20tokens%3A%20%7Btotal_tokens%3A%2C%7D%22)%0A%20%20%20%20print(f%22%20%20%20Tokens%20per%20second%3A%20%7Btotal_tokens%20%2F%20iteration_time.elapsed%3A%2C.0f%7D%22)%0A%20%20%20%20print(f%22%20%20%20Batches%20per%20second%3A%20%7Bbatch_count%20%2F%20iteration_time.elapsed%3A.2f%7D%22)%0A%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(%0A%20%20%20%20%20%20%20%20%22%22%22%0A%20%20%20%20%23%23%205.%20PyTorch%20Training%20Loop%20Integration%0A%0A%20%20%20%20Here's%20how%20to%20integrate%20SLAF%20DataLoader%20with%20PyTorch%20training%3A%0A%20%20%20%20%22%22%22%0A%20%20%20%20)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(dataloader)%3A%0A%20%20%20%20%23%20Demonstrate%20PyTorch%20integration%0A%20%20%20%20print(%22%F0%9F%94%A5%20PyTorch%20Training%20Loop%20Integration%22)%0A%20%20%20%20print(%22%3D%22%20*%2045)%0A%0A%20%20%20%20def%20demo_training_loop(dataloader)%3A%0A%20%20%20%20%20%20%20%20%23%20Check%20if%20PyTorch%20is%20available%0A%20%20%20%20%20%20%20%20try%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20import%20torch%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20TORCH_AVAILABLE%20%3D%20True%0A%20%20%20%20%20%20%20%20%20%20%20%20print(%22%E2%9C%85%20PyTorch%20is%20available%22)%0A%20%20%20%20%20%20%20%20except%20ImportError%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20TORCH_AVAILABLE%20%3D%20False%0A%20%20%20%20%20%20%20%20%20%20%20%20print(%22%E2%9A%A0%EF%B8%8F%20PyTorch%20not%20available%20-%20showing%20numpy-based%20approach%22)%0A%0A%20%20%20%20%20%20%20%20if%20TORCH_AVAILABLE%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20print(%22%5Cn1.%20PyTorch%20tensor%20conversion%3A%22)%0A%20%20%20%20%20%20%20%20%20%20%20%20batch%20%3D%20next(iter(dataloader))%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Get%20device%20info%0A%20%20%20%20%20%20%20%20%20%20%20%20from%20slaf.ml.dataloaders%20import%20get_device_info%2C%20get_optimal_device%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20device_info%20%3D%20get_device_info()%0A%20%20%20%20%20%20%20%20%20%20%20%20optimal_device%20%3D%20get_optimal_device()%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%20%20%20Device%20info%3A%20%7Bdevice_info%7D%22)%0A%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%20%20%20Using%20device%3A%20%7Boptimal_device%7D%22)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Convert%20to%20PyTorch%20tensors%20on%20optimal%20device%0A%20%20%20%20%20%20%20%20%20%20%20%20input_ids_tensor%20%3D%20torch.tensor(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20batch%5B%22input_ids%22%5D%2C%20dtype%3Dtorch.long%2C%20device%3Doptimal_device%0A%20%20%20%20%20%20%20%20%20%20%20%20)%0A%20%20%20%20%20%20%20%20%20%20%20%20attention_mask_tensor%20%3D%20torch.tensor(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20batch%5B%22attention_mask%22%5D%2C%20dtype%3Dtorch.bool%2C%20device%3Doptimal_device%0A%20%20%20%20%20%20%20%20%20%20%20%20)%0A%20%20%20%20%20%20%20%20%20%20%20%20cell_ids_tensor%20%3D%20torch.tensor(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20batch%5B%22cell_ids%22%5D%2C%20dtype%3Dtorch.long%2C%20device%3Doptimal_device%0A%20%20%20%20%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20print(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20f%22%20%20%20Input%20IDs%20tensor%3A%20%7Binput_ids_tensor.shape%7D%2C%20%7Binput_ids_tensor.dtype%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20)%0A%20%20%20%20%20%20%20%20%20%20%20%20print(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20f%22%20%20%20Attention%20mask%20tensor%3A%20%7Battention_mask_tensor.shape%7D%2C%20%7Battention_mask_tensor.dtype%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20)%0A%20%20%20%20%20%20%20%20%20%20%20%20print(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20f%22%20%20%20Cell%20IDs%20tensor%3A%20%7Bcell_ids_tensor.shape%7D%2C%20%7Bcell_ids_tensor.dtype%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20print(%22%5Cn2.%20Simple%20training%20loop%20structure%3A%22)%0A%20%20%20%20%20%20%20%20%20%20%20%20print(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22%22%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Training%20loop%20example%20with%20smart%20device%20detection%0A%20%20%20%20%20%20%20%20%20%20%20%20from%20slaf.ml.dataloaders%20import%20get_optimal_device%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20device%20%3D%20get_optimal_device()%0A%20%20%20%20%20%20%20%20%20%20%20%20model%20%3D%20YourModel(vocab_size%3Dtokenizer.get_vocab_info()%5B'total_vocab_size'%5D)%0A%20%20%20%20%20%20%20%20%20%20%20%20model%20%3D%20model.to(device)%20%20%23%20Move%20model%20to%20optimal%20device%0A%20%20%20%20%20%20%20%20%20%20%20%20optimizer%20%3D%20torch.optim.AdamW(model.parameters()%2C%20lr%3D1e-4)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20for%20epoch%20in%20range(num_epochs)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20model.train()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20for%20batch%20in%20dataloader%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20DataLoader%20already%20provides%20tensors%20on%20optimal%20device%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20input_ids%20%3D%20batch%5B%22input_ids%22%5D%20%20%23%20Already%20on%20device%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20attention_mask%20%3D%20batch%5B%22attention_mask%22%5D%20%20%23%20Already%20on%20device%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Forward%20pass%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20outputs%20%3D%20model(input_ids%3Dinput_ids%2C%20attention_mask%3Dattention_mask)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20loss%20%3D%20outputs.loss%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Backward%20pass%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20optimizer.zero_grad()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20loss.backward()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20optimizer.step()%0A%20%20%20%20%20%20%20%20%20%20%20%20%22%22%22%0A%20%20%20%20%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20%20%20%20%20else%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20print(%22%5Cn1.%20Numpy-based%20approach%3A%22)%0A%20%20%20%20%20%20%20%20%20%20%20%20batch%20%3D%20next(iter(dataloader))%0A%20%20%20%20%20%20%20%20%20%20%20%20print(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20f%22%20%20%20Input%20IDs%3A%20%7Bbatch%5B'input_ids'%5D.shape%7D%2C%20%7Bbatch%5B'input_ids'%5D.dtype%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20)%0A%20%20%20%20%20%20%20%20%20%20%20%20print(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20f%22%20%20%20Attention%20mask%3A%20%7Bbatch%5B'attention_mask'%5D.shape%7D%2C%20%7Bbatch%5B'attention_mask'%5D.dtype%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20)%0A%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%20%20%20Cell%20IDs%3A%20%7Bbatch%5B'cell_ids'%5D.shape%7D%2C%20%7Bbatch%5B'cell_ids'%5D.dtype%7D%22)%0A%0A%20%20%20%20demo_training_loop(dataloader)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(%0A%20%20%20%20%20%20%20%20%22%22%22%0A%20%20%20%20%23%23%206.%20Custom%20DataLoader%20Implementation%0A%0A%20%20%20%20Learn%20how%20to%20create%20custom%20DataLoaders%20for%20specific%20use%20cases%3A%0A%20%20%20%20%22%22%22%0A%20%20%20%20)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(SLAFTokenizer%2C%20np%2C%20slaf)%3A%0A%20%20%20%20%23%20Custom%20DataLoader%20implementation%0A%20%20%20%20print(%22%F0%9F%94%A7%20Custom%20DataLoader%20Implementation%22)%0A%20%20%20%20print(%22%3D%22%20*%2040)%0A%0A%20%20%20%20class%20CustomSLAFDataLoader%3A%0A%20%20%20%20%20%20%20%20%22%22%22Custom%20DataLoader%20with%20specific%20functionality%22%22%22%0A%0A%20%20%20%20%20%20%20%20def%20__init__(%0A%20%20%20%20%20%20%20%20%20%20%20%20self%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20slaf_array%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20batch_size%3D32%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20max_genes%3D100%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20tokenizer_type%3D%22geneformer%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20**tokenizer_kwargs%2C%0A%20%20%20%20%20%20%20%20)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20self.slaf_array%20%3D%20slaf_array%0A%20%20%20%20%20%20%20%20%20%20%20%20self.batch_size%20%3D%20batch_size%0A%20%20%20%20%20%20%20%20%20%20%20%20self.max_genes%20%3D%20max_genes%0A%20%20%20%20%20%20%20%20%20%20%20%20self.tokenizer_type%20%3D%20tokenizer_type%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Initialize%20tokenizer%0A%20%20%20%20%20%20%20%20%20%20%20%20self.tokenizer%20%3D%20SLAFTokenizer(slaf_array%2C%20**tokenizer_kwargs)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Get%20cell%20ranges%20for%20batching%0A%20%20%20%20%20%20%20%20%20%20%20%20self.cell_ranges%20%3D%20self._get_cell_ranges()%0A%0A%20%20%20%20%20%20%20%20def%20_get_cell_ranges(self)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%22%22%22Get%20cell%20integer%20ID%20ranges%20for%20batching%22%22%22%0A%20%20%20%20%20%20%20%20%20%20%20%20max_cell_id%20%3D%20int(self.slaf_array.obs%5B%22cell_integer_id%22%5D.astype(int).max())%0A%20%20%20%20%20%20%20%20%20%20%20%20ranges%20%3D%20%5B%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20for%20start%20in%20range(0%2C%20max_cell_id%20%2B%201%2C%20self.batch_size)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20end%20%3D%20min(start%20%2B%20self.batch_size%2C%20max_cell_id%20%2B%201)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20ranges.append((start%2C%20end))%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20ranges%0A%0A%20%20%20%20%20%20%20%20def%20__iter__(self)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%22%22%22Iterate%20through%20batches%22%22%22%0A%20%20%20%20%20%20%20%20%20%20%20%20for%20cell_range%20in%20self.cell_ranges%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Tokenize%20based%20on%20type%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20self.tokenizer_type%20%3D%3D%20%22geneformer%22%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20tokens%20%3D%20self.tokenizer.tokenize_geneformer(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20cell_integer_id_range%3Dcell_range%2C%20max_genes%3Dself.max_genes%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20elif%20self.tokenizer_type%20%3D%3D%20%22scgpt%22%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20tokens%20%3D%20self.tokenizer.tokenize_scgpt(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20cell_integer_id_range%3Dcell_range%2C%20max_genes%3Dself.max_genes%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20else%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20raise%20ValueError(f%22Unknown%20tokenizer%20type%3A%20%7Bself.tokenizer_type%7D%22)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20not%20tokens%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20continue%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Convert%20to%20numpy%20arrays%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20batch_tensors%20%3D%20np.array(tokens%2C%20dtype%3Dnp.int64)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20attention_mask%20%3D%20batch_tensors%20!%3D%20self.tokenizer.special_tokens%5B%22PAD%22%5D%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Get%20cell%20IDs%20for%20this%20range%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20start_cell%2C%20end_cell%20%3D%20cell_range%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20cell_ids%20%3D%20list(range(start_cell%2C%20end_cell))%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20yield%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22input_ids%22%3A%20batch_tensors%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22attention_mask%22%3A%20attention_mask%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22cell_ids%22%3A%20np.array(cell_ids%5B%3A%20len(tokens)%5D%2C%20dtype%3Dnp.int64)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%0A%20%20%20%20%20%20%20%20def%20__len__(self)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20len(self.cell_ranges)%0A%0A%20%20%20%20%23%20Test%20custom%20DataLoader%0A%20%20%20%20print(%22%E2%9C%85%20Custom%20DataLoader%20created%22)%0A%0A%20%20%20%20custom_dataloader%20%3D%20CustomSLAFDataLoader(%0A%20%20%20%20%20%20%20%20slaf_array%3Dslaf%2C%0A%20%20%20%20%20%20%20%20batch_size%3D8%2C%0A%20%20%20%20%20%20%20%20max_genes%3D50%2C%0A%20%20%20%20%20%20%20%20tokenizer_type%3D%22geneformer%22%2C%0A%20%20%20%20%20%20%20%20vocab_size%3D1000%2C%0A%20%20%20%20)%0A%0A%20%20%20%20print(f%22%20%20%20Number%20of%20batches%3A%20%7Blen(custom_dataloader)%7D%22)%0A%0A%20%20%20%20%23%20Test%20iteration%0A%20%20%20%20batch%20%3D%20next(iter(custom_dataloader))%0A%20%20%20%20print(f%22%20%20%20First%20batch%20shape%3A%20%7Bbatch%5B'input_ids'%5D.shape%7D%22)%0A%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(%0A%20%20%20%20%20%20%20%20%22%22%22%0A%20%20%20%20%23%23%207.%20Advanced%20Tokenization%20Features%0A%0A%20%20%20%20Explore%20advanced%20tokenization%20features%20and%20optimizations%3A%0A%20%20%20%20%22%22%22%0A%20%20%20%20)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(np%2C%20time%2C%20tokenizer)%3A%0A%20%20%20%20%23%20Advanced%20tokenization%20features%0A%20%20%20%20print(%22%F0%9F%9A%80%20Advanced%20Tokenization%20Features%22)%0A%20%20%20%20print(%22%3D%22%20*%2040)%0A%0A%20%20%20%20def%20demo_advanced_tokenization()%3A%0A%20%20%20%20%20%20%20%20print(%221.%20Different%20max_genes%20settings%3A%22)%0A%20%20%20%20%20%20%20%20for%20max_genes%20in%20%5B25%2C%2050%2C%20100%5D%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20tokens%20%3D%20tokenizer.tokenize_geneformer((0%2C%2020)%2C%20max_genes%3Dmax_genes)%0A%20%20%20%20%20%20%20%20%20%20%20%20avg_length%20%3D%20np.mean(%5Blen(seq)%20for%20seq%20in%20tokens%5D)%0A%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%20%20%20max_genes%3D%7Bmax_genes%7D%3A%20avg_length%3D%7Bavg_length%3A.1f%7D%22)%0A%0A%20%20%20%20%20%20%20%20print(%22%5Cn2.%20Different%20percentile%20filtering%3A%22)%0A%20%20%20%20%20%20%20%20for%20percentile%20in%20%5BNone%2C%205%2C%2010%2C%2020%5D%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20tokens%20%3D%20tokenizer.tokenize_geneformer(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20(0%2C%2020)%2C%20max_genes%3D50%2C%20min_percentile%3Dpercentile%0A%20%20%20%20%20%20%20%20%20%20%20%20)%0A%20%20%20%20%20%20%20%20%20%20%20%20avg_length%20%3D%20np.mean(%5Blen(seq)%20for%20seq%20in%20tokens%5D)%0A%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%20%20%20min_percentile%3D%7Bpercentile%7D%3A%20avg_length%3D%7Bavg_length%3A.1f%7D%22)%0A%0A%20%20%20%20%20%20%20%20print(%22%5Cn3.%20SQL%20vs%20Python%20binning%20for%20scGPT%3A%22)%0A%20%20%20%20%20%20%20%20%23%20SQL%20binning%0A%20%20%20%20%20%20%20%20start_time%20%3D%20time.time()%0A%20%20%20%20%20%20%20%20_%20%3D%20tokenizer.tokenize_scgpt((0%2C%2020)%2C%20max_genes%3D25%2C%20use_sql_binning%3DTrue)%0A%20%20%20%20%20%20%20%20sql_time%20%3D%20time.time()%20-%20start_time%0A%0A%20%20%20%20%20%20%20%20%23%20Python%20binning%0A%20%20%20%20%20%20%20%20start_time%20%3D%20time.time()%0A%20%20%20%20%20%20%20%20_%20%3D%20tokenizer.tokenize_scgpt((0%2C%2020)%2C%20max_genes%3D25%2C%20use_sql_binning%3DFalse)%0A%20%20%20%20%20%20%20%20python_time%20%3D%20time.time()%20-%20start_time%0A%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20SQL%20binning%3A%20%7Bsql_time%3A.4f%7Ds%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20Python%20binning%3A%20%7Bpython_time%3A.4f%7Ds%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20Speedup%3A%20%7Bpython_time%20%2F%20sql_time%3A.2f%7Dx%22)%0A%0A%20%20%20%20demo_advanced_tokenization()%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(%0A%20%20%20%20%20%20%20%20%22%22%22%0A%20%20%20%20%23%23%208.%20Memory%20and%20Performance%20Optimization%0A%0A%20%20%20%20Learn%20how%20to%20optimize%20memory%20usage%20and%20performance%20for%20large-scale%20training%3A%0A%20%20%20%20%22%22%22%0A%20%20%20%20)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(SLAFDataLoader%2C%20slaf%2C%20time)%3A%0A%20%20%20%20%23%20Memory%20and%20performance%20optimization%0A%20%20%20%20print(%22%F0%9F%92%BE%20Memory%20and%20Performance%20Optimization%22)%0A%20%20%20%20print(%22%3D%22%20*%2045)%0A%0A%20%20%20%20import%20gc%0A%0A%20%20%20%20import%20psutil%0A%0A%20%20%20%20def%20get_memory_usage()%3A%0A%20%20%20%20%20%20%20%20%22%22%22Get%20current%20memory%20usage%20in%20MB%22%22%22%0A%20%20%20%20%20%20%20%20process%20%3D%20psutil.Process()%0A%20%20%20%20%20%20%20%20return%20process.memory_info().rss%20%2F%201024%20%2F%201024%0A%0A%20%20%20%20def%20demo_memory_and_performance_optimization()%3A%0A%20%20%20%20%20%20%20%20print(%221.%20Memory%20usage%20comparison%3A%22)%0A%0A%20%20%20%20%20%20%20%20%23%20Baseline%20memory%0A%20%20%20%20%20%20%20%20gc.collect()%0A%20%20%20%20%20%20%20%20baseline_memory%20%3D%20get_memory_usage()%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20Baseline%20memory%3A%20%7Bbaseline_memory%3A.1f%7D%20MB%22)%0A%0A%20%20%20%20%20%20%20%20%23%20Memory%20with%20different%20batch%20sizes%0A%20%20%20%20%20%20%20%20for%20batch_size%20in%20%5B8%2C%2016%2C%2032%5D%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20gc.collect()%0A%20%20%20%20%20%20%20%20%20%20%20%20start_memory%20%3D%20get_memory_usage()%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20dataloader%20%3D%20SLAFDataLoader(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20slaf_array%3Dslaf%2C%20batch_size%3Dbatch_size%2C%20max_genes%3D100%2C%20vocab_size%3D1000%0A%20%20%20%20%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Process%20one%20batch%0A%20%20%20%20%20%20%20%20%20%20%20%20_%20%3D%20next(iter(dataloader))%0A%20%20%20%20%20%20%20%20%20%20%20%20end_memory%20%3D%20get_memory_usage()%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20print(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20f%22%20%20%20Batch%20size%20%7Bbatch_size%7D%3A%20%7Bend_memory%3A.1f%7D%20MB%20(%2B%7Bend_memory%20-%20start_memory%3A.1f%7D%20MB)%22%0A%20%20%20%20%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20%20%20%20%20print(%22%5Cn2.%20Performance%20with%20different%20settings%3A%22)%0A%0A%20%20%20%20%20%20%20%20%23%20Test%20different%20configurations%0A%20%20%20%20%20%20%20%20configs%20%3D%20%5B%0A%20%20%20%20%20%20%20%20%20%20%20%20%7B%22batch_size%22%3A%208%2C%20%22max_genes%22%3A%2050%2C%20%22description%22%3A%20%22Small%20batches%22%7D%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%7B%22batch_size%22%3A%2016%2C%20%22max_genes%22%3A%20100%2C%20%22description%22%3A%20%22Medium%20batches%22%7D%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%7B%22batch_size%22%3A%2032%2C%20%22max_genes%22%3A%20200%2C%20%22description%22%3A%20%22Large%20batches%22%7D%2C%0A%20%20%20%20%20%20%20%20%5D%0A%0A%20%20%20%20%20%20%20%20for%20config%20in%20configs%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20dataloader%20%3D%20SLAFDataLoader(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20slaf_array%3Dslaf%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20**%7Bk%3A%20v%20for%20k%2C%20v%20in%20config.items()%20if%20k%20!%3D%20%22description%22%7D%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20start_time%20%3D%20time.time()%0A%20%20%20%20%20%20%20%20%20%20%20%20batch_count%20%3D%200%0A%20%20%20%20%20%20%20%20%20%20%20%20for%20_%20in%20dataloader%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20batch_count%20%2B%3D%201%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20batch_count%20%3E%3D%203%3A%20%20%23%20Test%20first%203%20batches%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20break%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20elapsed_time%20%3D%20time.time()%20-%20start_time%0A%20%20%20%20%20%20%20%20%20%20%20%20print(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20f%22%20%20%20%7Bconfig%5B'description'%5D%7D%3A%20%7Belapsed_time%3A.4f%7Ds%20for%20%7Bbatch_count%7D%20batches%22%0A%20%20%20%20%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20demo_memory_and_performance_optimization()%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(%0A%20%20%20%20%20%20%20%20%22%22%22%0A%20%20%20%20%23%23%209.%20Production%20Training%20Workflow%0A%0A%20%20%20%20Complete%20example%20of%20a%20production-ready%20training%20workflow%3A%0A%20%20%20%20%22%22%22%0A%20%20%20%20)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(SLAFDataLoader%2C%20SLAFTokenizer%2C%20slaf)%3A%0A%20%20%20%20%23%20Production%20training%20workflow%0A%20%20%20%20print(%22%F0%9F%8F%AD%20Production%20Training%20Workflow%22)%0A%20%20%20%20print(%22%3D%22%20*%2040)%0A%0A%20%20%20%20def%20create_production_dataloaders(%0A%20%20%20%20%20%20%20%20slaf_array%2C%20train_ratio%3D0.8%2C%20val_ratio%3D0.1%2C%20test_ratio%3D0.1%0A%20%20%20%20)%3A%0A%20%20%20%20%20%20%20%20%22%22%22Create%20train%2Fval%2Ftest%20dataloaders%22%22%22%0A%0A%20%20%20%20%20%20%20%20%23%20Get%20total%20number%20of%20cells%0A%20%20%20%20%20%20%20%20total_cells%20%3D%20len(slaf_array.obs)%0A%20%20%20%20%20%20%20%20_%20%3D%20int(total_cells%20*%20train_ratio)%20%20%23%20train_size%0A%20%20%20%20%20%20%20%20_%20%3D%20int(total_cells%20*%20val_ratio)%20%20%23%20val_size%0A%0A%20%20%20%20%20%20%20%20%23%20Create%20tokenizer%0A%20%20%20%20%20%20%20%20tokenizer%20%3D%20SLAFTokenizer(%0A%20%20%20%20%20%20%20%20%20%20%20%20slaf_array%3Dslaf_array%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20vocab_size%3D10000%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20n_expression_bins%3D50%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20chunk_size%3D1024%2C%0A%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20%20%20%20%20print(%0A%20%20%20%20%20%20%20%20%20%20%20%20f%22%E2%9C%85%20Created%20tokenizer%20with%20%7Btokenizer.get_vocab_info()%5B'total_vocab_size'%5D%7D%20total%20tokens%22%0A%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20%20%20%20%20%23%20Create%20dataloaders%20(in%20production%2C%20you'd%20use%20proper%20splits)%0A%20%20%20%20%20%20%20%20train_dataloader%20%3D%20SLAFDataLoader(%0A%20%20%20%20%20%20%20%20%20%20%20%20slaf_array%3Dslaf_array%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20tokenizer_type%3D%22geneformer%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20batch_size%3D32%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20max_genes%3D512%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20vocab_size%3D10000%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20n_expression_bins%3D50%2C%0A%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20%20%20%20%20val_dataloader%20%3D%20SLAFDataLoader(%0A%20%20%20%20%20%20%20%20%20%20%20%20slaf_array%3Dslaf_array%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20tokenizer_type%3D%22geneformer%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20batch_size%3D32%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20max_genes%3D512%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20vocab_size%3D10000%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20n_expression_bins%3D50%2C%0A%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20%20%20%20%20return%20train_dataloader%2C%20val_dataloader%2C%20tokenizer%0A%0A%20%20%20%20%23%20Create%20production%20dataloaders%0A%20%20%20%20train_dl%2C%20val_dl%2C%20prod_tokenizer%20%3D%20create_production_dataloaders(slaf)%0A%0A%20%20%20%20print(%22%5Cn%F0%9F%93%8A%20Production%20Setup%3A%22)%0A%20%20%20%20print(f%22%20%20%20Train%20batches%3A%20%7Blen(train_dl)%7D%22)%0A%20%20%20%20print(f%22%20%20%20Validation%20batches%3A%20%7Blen(val_dl)%7D%22)%0A%20%20%20%20print(f%22%20%20%20Batch%20size%3A%20%7Btrain_dl.batch_size%7D%22)%0A%20%20%20%20print(f%22%20%20%20Max%20genes%3A%20%7Btrain_dl.max_genes%7D%22)%0A%0A%20%20%20%20%23%20Test%20production%20workflow%0A%20%20%20%20print(%22%5Cn%F0%9F%A7%AA%20Testing%20production%20workflow%3A%22)%0A%0A%20%20%20%20%23%20Test%20training%20batch%0A%20%20%20%20train_batch%20%3D%20next(iter(train_dl))%0A%20%20%20%20print(f%22%20%20%20Training%20batch%20shape%3A%20%7Btrain_batch%5B'input_ids'%5D.shape%7D%22)%0A%0A%20%20%20%20%23%20Test%20validation%20batch%0A%20%20%20%20val_batch%20%3D%20next(iter(val_dl))%0A%20%20%20%20print(f%22%20%20%20Validation%20batch%20shape%3A%20%7Bval_batch%5B'input_ids'%5D.shape%7D%22)%0A%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(%0A%20%20%20%20%20%20%20%20%22%22%22%0A%20%20%20%20%23%23%2010.%20Best%20Practices%20for%20ML%20Training%0A%0A%20%20%20%20Key%20best%20practices%20for%20using%20SLAF%20in%20ML%20training%3A%0A%20%20%20%20%22%22%22%0A%20%20%20%20)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_()%3A%0A%20%20%20%20%23%20Best%20practices%20for%20ML%20training%0A%20%20%20%20print(%22%F0%9F%92%A1%20Best%20Practices%20for%20ML%20Training%22)%0A%20%20%20%20print(%22%3D%22%20*%2040)%0A%0A%20%20%20%20print(%221.%20Tokenizer%20Configuration%3A%22)%0A%20%20%20%20print(%22%20%20%20%E2%9C%85%20Choose%20appropriate%20vocab_size%20based%20on%20your%20dataset%22)%0A%20%20%20%20print(%22%20%20%20%E2%9C%85%20Use%20n_expression_bins%3D50%20for%20fine-grained%20expression%20modeling%22)%0A%20%20%20%20print(%22%20%20%20%E2%9C%85%20Set%20chunk_size%20based%20on%20available%20memory%22)%0A%0A%20%20%20%20print(%22%5Cn2.%20DataLoader%20Configuration%3A%22)%0A%20%20%20%20print(%22%20%20%20%E2%9C%85%20Start%20with%20small%20batch_size%20and%20increase%20gradually%22)%0A%20%20%20%20print(%22%20%20%20%E2%9C%85%20Use%20max_genes%20appropriate%20for%20your%20model%20architecture%22)%0A%20%20%20%20print(%22%20%20%20%E2%9C%85%20Set%20num_workers%20based%20on%20CPU%20cores%22)%0A%0A%20%20%20%20print(%22%5Cn3.%20Performance%20Optimization%3A%22)%0A%20%20%20%20print(%22%20%20%20%E2%9C%85%20Use%20SQL%20binning%20for%20scGPT%20tokenization%22)%0A%20%20%20%20print(%22%20%20%20%E2%9C%85%20Leverage%20percentile%20filtering%20for%20Geneformer%22)%0A%20%20%20%20print(%22%20%20%20%E2%9C%85%20Monitor%20memory%20usage%20during%20training%22)%0A%0A%20%20%20%20print(%22%5Cn4.%20Training%20Workflow%3A%22)%0A%20%20%20%20print(%22%20%20%20%E2%9C%85%20Create%20separate%20train%2Fval%2Ftest%20splits%22)%0A%20%20%20%20print(%22%20%20%20%E2%9C%85%20Use%20consistent%20tokenizer%20across%20splits%22)%0A%20%20%20%20print(%22%20%20%20%E2%9C%85%20Implement%20proper%20error%20handling%22)%0A%0A%20%20%20%20print(%22%5Cn5.%20Production%20Considerations%3A%22)%0A%20%20%20%20print(%22%20%20%20%E2%9C%85%20Use%20appropriate%20batch%20sizes%20for%20your%20hardware%22)%0A%20%20%20%20print(%22%20%20%20%E2%9C%85%20Implement%20checkpointing%20for%20long%20training%20runs%22)%0A%20%20%20%20print(%22%20%20%20%E2%9C%85%20Monitor%20tokenization%20throughput%22)%0A%20%20%20%20print(%22%20%20%20%E2%9C%85%20Consider%20distributed%20training%20for%20large%20datasets%22)%0A%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(%0A%20%20%20%20%20%20%20%20%22%22%22%0A%20%20%20%20%23%23%20Summary%0A%0A%20%20%20%20**What%20you've%20learned%20about%20SLAF%20ML%20Training%3A**%0A%0A%20%20%20%201.%20**Tokenizer%20Configuration**%3A%20Customize%20vocabulary%20size%2C%20expression%20bins%2C%20and%20chunking%0A%20%20%20%202.%20**Tokenization%20Strategies**%3A%20Geneformer%20and%20scGPT%20formats%20with%20different%20performance%20characteristics%0A%20%20%20%203.%20**DataLoader%20Integration**%3A%20High-performance%20data%20loading%20with%20PyTorch%20compatibility%0A%20%20%20%204.%20**Performance%20Optimization**%3A%20SQL-level%20performance%20with%20memory%20efficiency%0A%20%20%20%205.%20**Custom%20Implementation**%3A%20How%20to%20build%20custom%20DataLoaders%20for%20specific%20needs%0A%20%20%20%206.%20**Production%20Workflow**%3A%20Complete%20training%20pipeline%20setup%0A%20%20%20%207.%20**Best%20Practices**%3A%20Guidelines%20for%20optimal%20ML%20training%20performance%0A%20%20%20%20%22%22%22%0A%20%20%20%20)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_()%3A%0A%20%20%20%20return%0A%0A%0Aif%20__name__%20%3D%3D%20%22__main__%22%3A%0A%20%20%20%20app.run()%0A
</marimo-code>

<marimo-code-hash hidden="">33bd633921c20a9e878d8116973bc022297e8317ec3386a3d82612455563a4f5</marimo-code-hash>
</body>
</html>
