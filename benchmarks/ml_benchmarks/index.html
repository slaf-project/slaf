<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Sparse Lazy Array Format - High-performance single-cell data storage and analysis"><meta name=author content="Pavan Ramkumar"><link href=https://slaf-project.github.io/slaf/benchmarks/ml_benchmarks/ rel=canonical><link href=../bioinformatics_benchmarks/ rel=prev><link href=../../api/core/ rel=next><link rel=icon href=../../assets/slaf-icon-transparent-dark-mono.svg><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.7.1"><title>For ML Engineers - SLAF Documentation</title><link rel=stylesheet href=../../assets/stylesheets/main.484c7ddc.min.css><link rel=stylesheet href=../../assets/stylesheets/palette.ab4e12ef.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../../assets/_mkdocstrings.css><link rel=stylesheet href=../../stylesheets/extra.css><link rel=stylesheet href=../../stylesheets/logo-theme.css><script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><script id=__analytics>function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config",""),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script><script>"undefined"!=typeof __md_analytics&&__md_analytics()</script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#ml-benchmarks-slaf-vs-state-of-the-art-dataloaders class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class="md-header md-header--shadow" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../.. title="SLAF Documentation" class="md-header__button md-logo" aria-label="SLAF Documentation" data-md-component=logo> <img src=../../assets/slaf-icon-transparent-dark-mono.svg alt=logo> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> SLAF Documentation </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> For ML Engineers </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to dark mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> <input class=md-option data-md-color-media data-md-color-scheme=slate data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to light mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/slaf-project/slaf title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg> </div> <div class=md-source__repository> slaf-project/slaf </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../.. title="SLAF Documentation" class="md-nav__button md-logo" aria-label="SLAF Documentation" data-md-component=logo> <img src=../../assets/slaf-icon-transparent-dark-mono.svg alt=logo> </a> SLAF Documentation </label> <div class=md-nav__source> <a href=https://github.com/slaf-project/slaf title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg> </div> <div class=md-source__repository> slaf-project/slaf </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../.. class=md-nav__link> <span class=md-ellipsis> Home </span> </a> </li> <li class=md-nav__item> <a href=../../getting-started/quickstart/ class=md-nav__link> <span class=md-ellipsis> Quick Start </span> </a> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3> <label class=md-nav__link for=__nav_3 id=__nav_3_label tabindex> <span class=md-ellipsis> User Guide </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> User Guide </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../user-guide/how-slaf-works/ class=md-nav__link> <span class=md-ellipsis> How SLAF Works </span> </a> </li> <li class=md-nav__item> <a href=../../user-guide/migrating-to-slaf/ class=md-nav__link> <span class=md-ellipsis> Migrating to SLAF </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4> <label class=md-nav__link for=__nav_4 id=__nav_4_label tabindex> <span class=md-ellipsis> Examples </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_4_label aria-expanded=false> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> Examples </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../examples/getting-started/ class=md-nav__link> <span class=md-ellipsis> Getting Started </span> </a> </li> <li class=md-nav__item> <a href=../../examples/lazy-processing/ class=md-nav__link> <span class=md-ellipsis> Lazy Processing </span> </a> </li> <li class=md-nav__item> <a href=../../examples/ml-training/ class=md-nav__link> <span class=md-ellipsis> ML Training </span> </a> </li> <li class=md-nav__item> <a href=../../examples/sql-queries/ class=md-nav__link> <span class=md-ellipsis> SQL Queries </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5 checked> <label class=md-nav__link for=__nav_5 id=__nav_5_label tabindex> <span class=md-ellipsis> Benchmarks </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_5_label aria-expanded=true> <label class=md-nav__title for=__nav_5> <span class="md-nav__icon md-icon"></span> Benchmarks </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../ class=md-nav__link> <span class=md-ellipsis> Overview </span> </a> </li> <li class=md-nav__item> <a href=../bioinformatics_benchmarks/ class=md-nav__link> <span class=md-ellipsis> For Bioinformaticians </span> </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> For ML Engineers </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> For ML Engineers </span> </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#motivation class=md-nav__link> <span class=md-ellipsis> Motivation </span> </a> </li> <li class=md-nav__item> <a href=#dataset-and-hardware class=md-nav__link> <span class=md-ellipsis> Dataset and Hardware </span> </a> <nav class=md-nav aria-label="Dataset and Hardware"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#dataset-tahoe-100m class=md-nav__link> <span class=md-ellipsis> Dataset: Tahoe-100M </span> </a> </li> <li class=md-nav__item> <a href=#conversion-and-optimization class=md-nav__link> <span class=md-ellipsis> Conversion and Optimization </span> </a> </li> <li class=md-nav__item> <a href=#hardware-configuration class=md-nav__link> <span class=md-ellipsis> Hardware Configuration </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#internal-benchmarks class=md-nav__link> <span class=md-ellipsis> Internal Benchmarks </span> </a> <nav class=md-nav aria-label="Internal Benchmarks"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#methodology class=md-nav__link> <span class=md-ellipsis> Methodology </span> </a> </li> <li class=md-nav__item> <a href=#tokenization-strategy-comparison class=md-nav__link> <span class=md-ellipsis> Tokenization Strategy Comparison </span> </a> </li> <li class=md-nav__item> <a href=#raw-mode-performance-scaling class=md-nav__link> <span class=md-ellipsis> Raw Mode Performance Scaling </span> </a> </li> <li class=md-nav__item> <a href=#fragment-vs-batch-loading-comparison class=md-nav__link> <span class=md-ellipsis> Fragment vs Batch Loading Comparison </span> </a> </li> <li class=md-nav__item> <a href=#tokenized-mode-tokenssec-scaling class=md-nav__link> <span class=md-ellipsis> Tokenized Mode: Tokens/sec Scaling </span> </a> </li> <li class=md-nav__item> <a href=#entropy-measurement-training-batch-randomness class=md-nav__link> <span class=md-ellipsis> Entropy Measurement: Training Batch Randomness </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#external-benchmarks class=md-nav__link> <span class=md-ellipsis> External Benchmarks </span> </a> <nav class=md-nav aria-label="External Benchmarks"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#alternate-dataloaders class=md-nav__link> <span class=md-ellipsis> Alternate Dataloaders </span> </a> </li> <li class=md-nav__item> <a href=#methodology_1 class=md-nav__link> <span class=md-ellipsis> Methodology </span> </a> </li> <li class=md-nav__item> <a href=#tier-1-raw-data-loading-comparison class=md-nav__link> <span class=md-ellipsis> Tier 1: Raw Data Loading Comparison </span> </a> </li> <li class=md-nav__item> <a href=#tier-2-gpu-ready-output-comparison class=md-nav__link> <span class=md-ellipsis> Tier 2: GPU-Ready Output Comparison </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#some-discrepancies class=md-nav__link> <span class=md-ellipsis> Some Discrepancies </span> </a> </li> <li class=md-nav__item> <a href=#conclusion class=md-nav__link> <span class=md-ellipsis> Conclusion </span> </a> <nav class=md-nav aria-label=Conclusion> <ul class=md-nav__list> <li class=md-nav__item> <a href=#cloud-native-architecture class=md-nav__link> <span class=md-ellipsis> Cloud-Native Architecture </span> </a> </li> <li class=md-nav__item> <a href=#gpu-throughput-requirements class=md-nav__link> <span class=md-ellipsis> GPU Throughput Requirements </span> </a> </li> <li class=md-nav__item> <a href=#high-concurrency-and-multi-user-training class=md-nav__link> <span class=md-ellipsis> High Concurrency and Multi-User Training </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_6> <label class=md-nav__link for=__nav_6 id=__nav_6_label tabindex> <span class=md-ellipsis> API Reference </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_6_label aria-expanded=false> <label class=md-nav__title for=__nav_6> <span class="md-nav__icon md-icon"></span> API Reference </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../api/core/ class=md-nav__link> <span class=md-ellipsis> Core </span> </a> </li> <li class=md-nav__item> <a href=../../api/data/ class=md-nav__link> <span class=md-ellipsis> Data </span> </a> </li> <li class=md-nav__item> <a href=../../api/integrations/ class=md-nav__link> <span class=md-ellipsis> Integrations </span> </a> </li> <li class=md-nav__item> <a href=../../api/ml/ class=md-nav__link> <span class=md-ellipsis> ML </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_7> <label class=md-nav__link for=__nav_7 id=__nav_7_label tabindex> <span class=md-ellipsis> Development </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_7_label aria-expanded=false> <label class=md-nav__title for=__nav_7> <span class="md-nav__icon md-icon"></span> Development </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../development/contributing/ class=md-nav__link> <span class=md-ellipsis> For Contributors </span> </a> </li> <li class=md-nav__item> <a href=../../development/maintaining/ class=md-nav__link> <span class=md-ellipsis> For Maintainers </span> </a> </li> <li class=md-nav__item> <a href=../../development/benchmarks/ class=md-nav__link> <span class=md-ellipsis> Benchmarks </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_8> <label class=md-nav__link for=__nav_8 id=__nav_8_label tabindex> <span class=md-ellipsis> Blog </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_8_label aria-expanded=false> <label class=md-nav__title for=__nav_8> <span class="md-nav__icon md-icon"></span> Blog </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../blog/ class=md-nav__link> <span class=md-ellipsis> Blog Home </span> </a> </li> <li class=md-nav__item> <a href=../../blog/huggingface/ class=md-nav__link> <span class=md-ellipsis> SLAF on Hugging Face </span> </a> </li> <li class=md-nav__item> <a href=../../blog/introducing-slaf/ class=md-nav__link> <span class=md-ellipsis> Introducing SLAF </span> </a> </li> <li class=md-nav__item> <a href=../../blog/blazing-fast-dataloaders/ class=md-nav__link> <span class=md-ellipsis> Blazing Fast Dataloaders </span> </a> </li> <li class=md-nav__item> <a href=../../blog/blazing-fast-dataloaders-2/ class=md-nav__link> <span class=md-ellipsis> Mixture of Scanners </span> </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#motivation class=md-nav__link> <span class=md-ellipsis> Motivation </span> </a> </li> <li class=md-nav__item> <a href=#dataset-and-hardware class=md-nav__link> <span class=md-ellipsis> Dataset and Hardware </span> </a> <nav class=md-nav aria-label="Dataset and Hardware"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#dataset-tahoe-100m class=md-nav__link> <span class=md-ellipsis> Dataset: Tahoe-100M </span> </a> </li> <li class=md-nav__item> <a href=#conversion-and-optimization class=md-nav__link> <span class=md-ellipsis> Conversion and Optimization </span> </a> </li> <li class=md-nav__item> <a href=#hardware-configuration class=md-nav__link> <span class=md-ellipsis> Hardware Configuration </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#internal-benchmarks class=md-nav__link> <span class=md-ellipsis> Internal Benchmarks </span> </a> <nav class=md-nav aria-label="Internal Benchmarks"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#methodology class=md-nav__link> <span class=md-ellipsis> Methodology </span> </a> </li> <li class=md-nav__item> <a href=#tokenization-strategy-comparison class=md-nav__link> <span class=md-ellipsis> Tokenization Strategy Comparison </span> </a> </li> <li class=md-nav__item> <a href=#raw-mode-performance-scaling class=md-nav__link> <span class=md-ellipsis> Raw Mode Performance Scaling </span> </a> </li> <li class=md-nav__item> <a href=#fragment-vs-batch-loading-comparison class=md-nav__link> <span class=md-ellipsis> Fragment vs Batch Loading Comparison </span> </a> </li> <li class=md-nav__item> <a href=#tokenized-mode-tokenssec-scaling class=md-nav__link> <span class=md-ellipsis> Tokenized Mode: Tokens/sec Scaling </span> </a> </li> <li class=md-nav__item> <a href=#entropy-measurement-training-batch-randomness class=md-nav__link> <span class=md-ellipsis> Entropy Measurement: Training Batch Randomness </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#external-benchmarks class=md-nav__link> <span class=md-ellipsis> External Benchmarks </span> </a> <nav class=md-nav aria-label="External Benchmarks"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#alternate-dataloaders class=md-nav__link> <span class=md-ellipsis> Alternate Dataloaders </span> </a> </li> <li class=md-nav__item> <a href=#methodology_1 class=md-nav__link> <span class=md-ellipsis> Methodology </span> </a> </li> <li class=md-nav__item> <a href=#tier-1-raw-data-loading-comparison class=md-nav__link> <span class=md-ellipsis> Tier 1: Raw Data Loading Comparison </span> </a> </li> <li class=md-nav__item> <a href=#tier-2-gpu-ready-output-comparison class=md-nav__link> <span class=md-ellipsis> Tier 2: GPU-Ready Output Comparison </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#some-discrepancies class=md-nav__link> <span class=md-ellipsis> Some Discrepancies </span> </a> </li> <li class=md-nav__item> <a href=#conclusion class=md-nav__link> <span class=md-ellipsis> Conclusion </span> </a> <nav class=md-nav aria-label=Conclusion> <ul class=md-nav__list> <li class=md-nav__item> <a href=#cloud-native-architecture class=md-nav__link> <span class=md-ellipsis> Cloud-Native Architecture </span> </a> </li> <li class=md-nav__item> <a href=#gpu-throughput-requirements class=md-nav__link> <span class=md-ellipsis> GPU Throughput Requirements </span> </a> </li> <li class=md-nav__item> <a href=#high-concurrency-and-multi-user-training class=md-nav__link> <span class=md-ellipsis> High Concurrency and Multi-User Training </span> </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <h1 id=ml-benchmarks-slaf-vs-state-of-the-art-dataloaders>ML Benchmarks: SLAF vs State-of-the-Art Dataloaders<a class=headerlink href=#ml-benchmarks-slaf-vs-state-of-the-art-dataloaders title="Permanent link">&para;</a></h1> <p>SLAF provides state-of-the-art (SOTA) performance in data loading throughput for machine learning workflows, reaching <strong>2.6x speedups</strong> relative to current SOTA, particularly for training transformer-based single-cell foundation models. What follows are comprehensive benchmarks comparing SLAF against state-of-the-art dataloaders including scDataset, BioNeMo SCDL, AnnDataLoader, AnnLoader, and TileDB DataLoader.</p> <h2 id=motivation><strong>Motivation</strong><a class=headerlink href=#motivation title="Permanent link">&para;</a></h2> <p>The goal of these benchmarks is to demonstrate that SLAF can stream tokens to modern GPUs at a rate sufficient to prevent idle time between training loops. For a 1B parameter model like scGPT, <em>fast enough</em> means delivering training batches <strong>within 50 ms</strong> to keep the GPU utilization high. This benchmark establishes SLAF's ability to meet the throughput requirements for efficient foundation model training on massive single-cell datasets.</p> <h2 id=dataset-and-hardware><strong>Dataset and Hardware</strong><a class=headerlink href=#dataset-and-hardware title="Permanent link">&para;</a></h2> <h3 id=dataset-tahoe-100m><strong>Dataset: Tahoe-100M</strong><a class=headerlink href=#dataset-tahoe-100m title="Permanent link">&para;</a></h3> <p>We downloaded one of the 7 h5ad files comprising the <a href=https://www.biorxiv.org/content/10.1101/2025.02.20.639398v1>Tahoe-100M dataset</a> made accessible by <a href=https://github.com/ArcInstitute/arc-virtual-cell-atlas/tree/main>ARC Institute</a>. This slice of the dataset contains 5,481,420 cells and 62,710 genes, with approximately 8B non-zero expression values. All benchmarks reported below used this dataset except for the TileDB dataloader since we couldn't successfully convert a 5M-cell dataset to the Tile DB SOMA Experiment format with 32G RAM. For the TileDB DataLoader alone, we report numbers on a smaller 50k-cell synthetic dataset.</p> <h3 id=conversion-and-optimization><strong>Conversion and Optimization</strong><a class=headerlink href=#conversion-and-optimization title="Permanent link">&para;</a></h3> <p>We used the <a href=../api/data/#slafconverter>SLAF converter</a> (see <a href=../../user-guide/migrating-to-slaf/ >Migrating to SLAF</a>) to convert the h5ad file to SLAF format. The Lance table fragments (Lance's term for partitions) were optimized for compression/query tradeoffs, with 5-10M non-zeros (rows) per fragment in the expression table. While inherently parallelizable, conversion is currently single process, and took about 10 minutes for this dataset.</p> <h3 id=hardware-configuration><strong>Hardware Configuration</strong><a class=headerlink href=#hardware-configuration title="Permanent link">&para;</a></h3> <ul> <li><strong>Machine</strong>: Apple MacBook Pro with M1 Max</li> <li><strong>Memory</strong>: 32 GB RAM</li> <li><strong>Storage</strong>: 1 TB NVMe SSD</li> <li><strong>OS</strong>: macOS 13.6.1</li> </ul> <div class="admonition note"> <p class=admonition-title>Note</p> <p>These benchmarks represent performance on a high-end laptop. Production deployments on dedicated servers with faster storage may show different performance characteristics. Likewise, performance from object storage to non-colocated compute might be worse.</p> </div> <h2 id=internal-benchmarks><strong>Internal Benchmarks</strong><a class=headerlink href=#internal-benchmarks title="Permanent link">&para;</a></h2> <h3 id=methodology><strong>Methodology</strong><a class=headerlink href=#methodology title="Permanent link">&para;</a></h3> <p>We used a batch size of 32 with an enhanced warmup and measurement procedure to ensure accurate and consistent results, especially for the Mixture of Scanners (MoS) strategy:</p> <ul> <li><strong>Initial Warmup</strong>: 15 batches to initialize the dataloader</li> <li><strong>Extended Warmup</strong>: 10 seconds to allow MoS to fully stabilize all fragment generators</li> <li><strong>Measurement Period</strong>: 40 seconds of pure performance measurement (excluding warmup time)</li> <li><strong>Total Runtime</strong>: 50 seconds per benchmark (10s warmup + 40s measurement)</li> </ul> <p>This methodology ensures that all dataloader strategies reach steady-state performance before measurement begins, eliminating variance from incomplete initialization.</p> <h3 id=tokenization-strategy-comparison><strong>Tokenization Strategy Comparison</strong><a class=headerlink href=#tokenization-strategy-comparison title="Permanent link">&para;</a></h3> <p>We benchmarked different tokenization strategies to understand the performance impact of various preprocessing options:</p> <table> <thead> <tr> <th>Tokenization Strategy</th> <th>Throughput (cells/sec)</th> <th>Throughput (tokens/sec)</th> </tr> </thead> <tbody> <tr> <td>scGPT with binning</td> <td>5,350</td> <td>10,967,687</td> </tr> <tr> <td>scGPT without binning</td> <td>5,157</td> <td>10,572,411</td> </tr> <tr> <td>Geneformer with percentile filtering</td> <td>6,999</td> <td>14,335,137</td> </tr> <tr> <td>Geneformer without percentile filtering</td> <td>6,494</td> <td>13,300,337</td> </tr> <tr> <td>Raw mode (no tokenization)</td> <td>22,323</td> <td>N/A</td> </tr> </tbody> </table> <p><strong>Tokenization Strategy Comparison:</strong></p> <div class="language-text highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a>Throughput (cells/sec)
</span><span id=__span-0-2><a id=__codelineno-0-2 name=__codelineno-0-2 href=#__codelineno-0-2></a>─────────────────────────────────────────────────────────
</span><span id=__span-0-3><a id=__codelineno-0-3 name=__codelineno-0-3 href=#__codelineno-0-3></a>Raw mode              ████████████████████████ 22,323
</span><span id=__span-0-4><a id=__codelineno-0-4 name=__codelineno-0-4 href=#__codelineno-0-4></a>Geneformer (filter)   ███████ 6,999
</span><span id=__span-0-5><a id=__codelineno-0-5 name=__codelineno-0-5 href=#__codelineno-0-5></a>Geneformer (no filt)  ██████ 6,494
</span><span id=__span-0-6><a id=__codelineno-0-6 name=__codelineno-0-6 href=#__codelineno-0-6></a>scGPT (binning)       █████ 5,350
</span><span id=__span-0-7><a id=__codelineno-0-7 name=__codelineno-0-7 href=#__codelineno-0-7></a>scGPT (no binning)    █████ 5,157
</span><span id=__span-0-8><a id=__codelineno-0-8 name=__codelineno-0-8 href=#__codelineno-0-8></a>─────────────────────────────────────────────────────────
</span><span id=__span-0-9><a id=__codelineno-0-9 name=__codelineno-0-9 href=#__codelineno-0-9></a>                      0    5K   10K   15K   20K   25K
</span></code></pre></div> <div class="admonition success"> <p class=admonition-title>Strategy Insights</p> <ul> <li><strong>Geneformer strategies</strong> show ~30% higher throughput than scGPT strategies</li> <li><strong>Binning and filtering</strong> have minimal performance impact (~7% difference)</li> <li><strong>Raw mode</strong> provides 3.4x higher throughput than tokenized modes, demonstrating the tokenization overhead</li> </ul> </div> <h3 id=raw-mode-performance-scaling><strong>Raw Mode Performance Scaling</strong><a class=headerlink href=#raw-mode-performance-scaling title="Permanent link">&para;</a></h3> <p>Raw mode bypasses tokenization and returns Polars DataFrames that have the exact schema as sparse CSR tensors, demonstrating SLAF's base data loading performance.</p> <table> <thead> <tr> <th>Batch Size</th> <th>Throughput (cells/sec)</th> <th>Total Cells</th> <th>Measurement Time (s)</th> </tr> </thead> <tbody> <tr> <td>32</td> <td>23,783</td> <td>713,577</td> <td>30.0</td> </tr> <tr> <td>64</td> <td>25,259</td> <td>765,957</td> <td>30.3</td> </tr> <tr> <td>128</td> <td>28,079</td> <td>842,394</td> <td>30.0</td> </tr> <tr> <td>256</td> <td>28,169</td> <td>850,146</td> <td>30.2</td> </tr> </tbody> </table> <p><strong>Raw Mode Batch Size Scaling:</strong></p> <div class="language-text highlight"><pre><span></span><code><span id=__span-1-1><a id=__codelineno-1-1 name=__codelineno-1-1 href=#__codelineno-1-1></a>Throughput (cells/sec)
</span><span id=__span-1-2><a id=__codelineno-1-2 name=__codelineno-1-2 href=#__codelineno-1-2></a>─────────────────────────────────────────────────────────
</span><span id=__span-1-3><a id=__codelineno-1-3 name=__codelineno-1-3 href=#__codelineno-1-3></a>Batch 256    ████████████████████████████████ 28,169
</span><span id=__span-1-4><a id=__codelineno-1-4 name=__codelineno-1-4 href=#__codelineno-1-4></a>Batch 128    ██████████████████████████████ 28,079
</span><span id=__span-1-5><a id=__codelineno-1-5 name=__codelineno-1-5 href=#__codelineno-1-5></a>Batch 64     ███████████████████████████ 25,259
</span><span id=__span-1-6><a id=__codelineno-1-6 name=__codelineno-1-6 href=#__codelineno-1-6></a>Batch 32     ██████████████████████████ 23,783
</span><span id=__span-1-7><a id=__codelineno-1-7 name=__codelineno-1-7 href=#__codelineno-1-7></a>─────────────────────────────────────────────────────────
</span><span id=__span-1-8><a id=__codelineno-1-8 name=__codelineno-1-8 href=#__codelineno-1-8></a>             0    5K   10K   15K   20K   25K   30K
</span></code></pre></div> <div class="admonition success"> <p class=admonition-title>Optimization Validation</p> <p>Raw mode throughput shows <strong>1.2x improvement</strong> from batch size 32 to 256, demonstrating that SLAF's data loading pipeline scales efficiently with larger batch sizes while maintaining high performance.</p> </div> <h3 id=fragment-vs-batch-loading-comparison><strong>Fragment vs Batch Loading Comparison</strong><a class=headerlink href=#fragment-vs-batch-loading-comparison title="Permanent link">&para;</a></h3> <p>SLAF supports two loading strategies: fragment-based and batch-based loading. Fragment-based loading processes entire Lance fragments at once, while batch-based loading processes multiple Lance batches sequentially.</p> <table> <thead> <tr> <th>Strategy</th> <th>Throughput (cells/sec)</th> <th>Total Cells</th> <th>Total Batches</th> </tr> </thead> <tbody> <tr> <td>Fragment-Based Loading</td> <td>22,472</td> <td>229,669</td> <td>7,180</td> </tr> <tr> <td>Batch-Based Loading</td> <td>24,354</td> <td>243,554</td> <td>8,038</td> </tr> </tbody> </table> <div class="admonition note"> <p class=admonition-title>Fragment Strategy Performance</p> <p>Batch-based loading shows modestly higher throughput than fragment-based loading in this benchmark, but test-retest repeatability shows high variance. The performance difference should not be overinterpreted as it may vary significantly across different runs and hardware configurations.</p> </div> <div class="admonition info"> <p class=admonition-title>Strategy Selection</p> <p>Mixture of Scanners (MoS) is the default strategy in SLAF for foundation model training, providing 88% of random entropy with only 3.2% throughput penalty. Sequential loading is available for maximum throughput by setting <code>use_mixture_of_scanners=False, by_fragment=False</code> to the SLAFDataLoader for users who prioritize speed over entropy.</p> </div> <h3 id=tokenized-mode-tokenssec-scaling><strong>Tokenized Mode: Tokens/sec Scaling</strong><a class=headerlink href=#tokenized-mode-tokenssec-scaling title="Permanent link">&para;</a></h3> <p>Tokenized mode provides pre-tokenized sequences ready for GPU training, demonstrating SLAF's end-to-end pipeline performance.</p> <table> <thead> <tr> <th>Batch Size</th> <th>Throughput (cells/sec)</th> <th>Throughput (tokens/sec)</th> <th>Total Cells</th> <th>Measurement Time (s)</th> </tr> </thead> <tbody> <tr> <td>32</td> <td>7,141</td> <td>14,624,846</td> <td>215,990</td> <td>30.2</td> </tr> <tr> <td>64</td> <td>7,147</td> <td>14,637,356</td> <td>223,872</td> <td>31.3</td> </tr> <tr> <td>128</td> <td>7,309</td> <td>14,969,420</td> <td>224,663</td> <td>30.7</td> </tr> <tr> <td>256</td> <td>7,269</td> <td>14,885,945</td> <td>224,511</td> <td>30.9</td> </tr> </tbody> </table> <p><strong>Tokenized Mode Throughput Scaling:</strong></p> <div class="language-text highlight"><pre><span></span><code><span id=__span-2-1><a id=__codelineno-2-1 name=__codelineno-2-1 href=#__codelineno-2-1></a>Throughput (tokens/sec, millions)
</span><span id=__span-2-2><a id=__codelineno-2-2 name=__codelineno-2-2 href=#__codelineno-2-2></a>─────────────────────────────────────────────────────────
</span><span id=__span-2-3><a id=__codelineno-2-3 name=__codelineno-2-3 href=#__codelineno-2-3></a>Batch 128    ████████████████████████████████ 14.97M
</span><span id=__span-2-4><a id=__codelineno-2-4 name=__codelineno-2-4 href=#__codelineno-2-4></a>Batch 256   ███████████████████████████████ 14.89M
</span><span id=__span-2-5><a id=__codelineno-2-5 name=__codelineno-2-5 href=#__codelineno-2-5></a>Batch 64    ███████████████████████████████ 14.64M
</span><span id=__span-2-6><a id=__codelineno-2-6 name=__codelineno-2-6 href=#__codelineno-2-6></a>Batch 32    ███████████████████████████████ 14.62M
</span><span id=__span-2-7><a id=__codelineno-2-7 name=__codelineno-2-7 href=#__codelineno-2-7></a>─────────────────────────────────────────────────────────
</span><span id=__span-2-8><a id=__codelineno-2-8 name=__codelineno-2-8 href=#__codelineno-2-8></a>             0    3M    6M    9M   12M   15M   18M
</span></code></pre></div> <div class="admonition success"> <p class=admonition-title>Tokenization Efficiency</p> <p>Token throughput remains remarkably constant across batch sizes (1.0x scaling), demonstrating that SLAF's tokenization pipeline is well-optimized and not the bottleneck. This validates that tokens/sec is the meaningful metric for GPU training workloads.</p> </div> <h3 id=entropy-measurement-training-batch-randomness><strong>Entropy Measurement: Training Batch Randomness</strong><a class=headerlink href=#entropy-measurement-training-batch-randomness title="Permanent link">&para;</a></h3> <p>To ensure models don't converge to local minima due to biased and highly correlated training batches, we want to make training batches as random as possible. However, random reads are more expensive than sequential reads, so we need to balance randomness with performance.</p> <p>To address this challenge, we developed a novel dataloader strategy called the <strong>Mixture of Scanners (MoS)</strong> approach, which randomly tasks a small randomized group of scanners to populate a queue of training batches by reading from different starting points of the dataset. A deeper dive into our approach to optimize dataloaders is available <a href=../../blog/blazing-fast-dataloaders/ >here</a> and a more detailed write up of the MoS dataloader is <a href=../../blog/blazing-fast-dataloaders-2/ >here</a>.</p> <p>To measure entropy without using metadata, we simulate random cell IDs and measure L1 distance between pairs of cell IDs both within and across adjacent training batches for our different dataloaders to show how each dataloader strategy performs relative to a purely sequential (lowerbound) vs a truly random approach (upperbound).</p> <p>We ran a test on 10,000 batches with a batch_size of 32 from a 5.4M cell dataset and found these results:</p> <p><strong>Entropy Measurement Results:</strong></p> <table> <thead> <tr> <th>Strategy</th> <th>Within-Batch L1</th> <th>Across-Batch L1</th> </tr> </thead> <tbody> <tr> <td>sequential</td> <td>94.1</td> <td>104.5</td> </tr> <tr> <td>fragment</td> <td>1,643.5</td> <td>1,672.6</td> </tr> <tr> <td>mos</td> <td>1,608,648.2</td> <td>1,642,829.9</td> </tr> <tr> <td>random</td> <td>1,828,595.2</td> <td>1,824,468.9</td> </tr> </tbody> </table> <p><strong>Normalized Entropy Scores [0=Sequential, 1=Random]:</strong></p> <table> <thead> <tr> <th>Strategy</th> <th>Within-Batch L1</th> <th>Across-Batch L1</th> </tr> </thead> <tbody> <tr> <td>sequential</td> <td>0.000</td> <td>0.000</td> </tr> <tr> <td>fragment</td> <td>0.001</td> <td>0.001</td> </tr> <tr> <td>mos</td> <td>0.880</td> <td>0.900</td> </tr> </tbody> </table> <p><strong>Throughput Performance Results:</strong></p> <table> <thead> <tr> <th>Strategy</th> <th>Throughput (cells/sec)</th> <th>Total Cells</th> <th>Total Batches</th> </tr> </thead> <tbody> <tr> <td>sequential</td> <td>23,728</td> <td>711,990</td> <td>23,509</td> </tr> <tr> <td>fragment</td> <td>26,769</td> <td>803,072</td> <td>25,216</td> </tr> <tr> <td>mos</td> <td>22,972</td> <td>689,234</td> <td>21,546</td> </tr> </tbody> </table> <div class="admonition success"> <p class=admonition-title>Entropy Strategy Performance</p> <ul> <li><strong>Sequential loading</strong> provides the lowest entropy (0.000), with contiguous cell IDs from Lance batches</li> <li><strong>Fragment-based loading</strong> shows minimal improvement (0.001), processing complete Lance fragments for slightly higher entropy</li> <li><strong>Mixture of Scanners (MoS)</strong> achieves near-random entropy (0.88+), demonstrating effective randomization while maintaining high throughput</li> <li><strong>MoS approach</strong> provides <strong>88% of the entropy</strong> of truly random sampling while maintaining the performance benefits of structured data access</li> </ul> </div> <div class="admonition success"> <p class=admonition-title>Throughput Performance Analysis</p> <ul> <li><strong>Fragment-based loading</strong> achieves the highest throughput (26,769 cells/sec), showing <strong>12.8% improvement</strong> over sequential loading</li> <li><strong>MoS approach</strong> maintains competitive throughput (22,972 cells/sec), only <strong>3.2% slower</strong> than sequential loading despite providing 88% random entropy</li> <li><strong>Performance-entropy trade-off</strong>: MoS successfully balances high entropy (0.88) with minimal throughput penalty (3.2% vs sequential)</li> <li><strong>All strategies</strong> maintain excellent throughput (&gt;22K cells/sec), demonstrating SLAF's efficient data loading architecture</li> </ul> </div> <div class="admonition info"> <p class=admonition-title>Entropy Interpretation Guide</p> <ul> <li><strong>Within-Batch</strong>: How random are the cells within each batch</li> <li><strong>Across-Batch</strong>: How much batch composition changes between batches</li> <li><strong>L1 Distance</strong>: Mean absolute difference between cell ID pairs</li> <li><strong>Scores closer to 0</strong> = more sequential, <strong>closer to 1</strong> = more random</li> </ul> </div> <div class="admonition info"> <p class=admonition-title>MoS Implementation Benefits</p> <p>The Mixture of Scanners approach successfully balances the competing demands of training batch randomness and data loading performance. By using multiple scanners reading from different dataset locations, MoS achieves 88% of the entropy of truly random sampling without creating pre-randomized copies of datasets. The approach maintains 96.8% of sequential loading throughput while providing near-random batch composition, making it ideal for training foundation models that require both high throughput and effective batch randomization.</p> </div> <h2 id=external-benchmarks><strong>External Benchmarks</strong><a class=headerlink href=#external-benchmarks title="Permanent link">&para;</a></h2> <h3 id=alternate-dataloaders><strong>Alternate Dataloaders</strong><a class=headerlink href=#alternate-dataloaders title="Permanent link">&para;</a></h3> <p>We compared SLAF against six state-of-the-art dataloaders:</p> <ol> <li><strong><a href=https://annbatch.readthedocs.io/en/stable/index.html>annbatch</a></strong> - High-performance data loader for minibatching on-disk AnnData, co-developed by lamin and scverse</li> <li><strong><a href=https://anndata.readthedocs.io/en/latest/generated/anndata.experimental.AnnLoader.html>AnnLoader</a></strong> - Experimental PyTorch DataLoader for AnnData objects from <code>anndata.experimental</code></li> <li><strong><a href=https://docs.scvi-tools.org/en/stable/api/reference/scvi.dataloaders.AnnDataLoader.html>AnnDataLoader</a></strong> - From <a href=https://docs.scvi-tools.org/en/stable/index.html>scvi-tools</a>, designed for training variational autoencoder (VAE)-style models</li> <li><strong><a href=https://github.com/Kidara/scDataset/tree/main>scDataset</a></strong> - Recently released high-performance dataloader with multiprocessing support</li> <li><strong><a href=https://tiledbsoma.readthedocs.io/ >TileDB DataLoader</a></strong> - An internal custom PyTorch DataLoader for TileDB SOMA experiments</li> <li><strong><a href=https://docs.nvidia.com/bionemo-framework/2.0/user-guide/developer-guide/bionemo-scdl/bionemo-scdl-Overview/ >BioNeMo SCDL</a></strong> - NVIDIA's single-cell data loading framework for scalable training of foundation models</li> </ol> <h3 id=methodology_1><strong>Methodology</strong><a class=headerlink href=#methodology_1 title="Permanent link">&para;</a></h3> <p>To match the benchmarks from the <a href=https://arxiv.org/pdf/2506.01883>scDataset paper</a> as closely as possible, we used a <code>batch_size=64</code> across all comparisons. For scDataset itself, we used the optimal parameters in our hardware (<code>block_size=8</code>, <code>fetch_factor=64</code>, which were different from the ones found to be optimal in the paper). However, we couldn't use <code>num_workers=12</code> out of the box because h5ad datasets aren't pickle-able and PyTorch DataLoaders expect this since they use multiprocessing.</p> <p><strong>Enhanced Measurement Procedure</strong>: All external benchmarks now use the same enhanced measurement procedure as internal benchmarks for fair comparison:</p> <ul> <li><strong>Initial Warmup</strong>: 15 batches to initialize each dataloader</li> <li><strong>Extended Warmup</strong>: 10 seconds to allow all systems to reach steady state</li> <li><strong>Measurement Period</strong>: 30 seconds of pure performance measurement (excluding warmup time)</li> <li><strong>Total Runtime</strong>: 40 seconds per benchmark (10s warmup + 30s measurement)</li> </ul> <p>This ensures fair and consistent performance comparisons across all dataloader systems.</p> <h3 id=tier-1-raw-data-loading-comparison><strong>Tier 1: Raw Data Loading Comparison</strong><a class=headerlink href=#tier-1-raw-data-loading-comparison title="Permanent link">&para;</a></h3> <p>Raw data loading performance measures the base throughput of each system without any tokenization overhead. All benchmarks use <code>batch_size=64</code> for consistent comparison.</p> <table> <thead> <tr> <th>System</th> <th>Throughput (cells/sec)</th> </tr> </thead> <tbody> <tr> <td><strong>annbatch</strong></td> <td><strong>68,867</strong></td> </tr> <tr> <td><strong>SLAF</strong></td> <td><strong>22,399</strong></td> </tr> <tr> <td>BioNeMo SCDL</td> <td>2,976</td> </tr> <tr> <td>scDataset</td> <td>2,550</td> </tr> <tr> <td>TileDB DataLoader (MoS)</td> <td>601</td> </tr> <tr> <td>AnnDataLoader</td> <td>411</td> </tr> <tr> <td>AnnLoader</td> <td>251</td> </tr> </tbody> </table> <p><strong>Throughput Comparison Chart:</strong></p> <div class="language-text highlight"><pre><span></span><code><span id=__span-3-1><a id=__codelineno-3-1 name=__codelineno-3-1 href=#__codelineno-3-1></a>Throughput (cells/sec)
</span><span id=__span-3-2><a id=__codelineno-3-2 name=__codelineno-3-2 href=#__codelineno-3-2></a>─────────────────────────────────────────────────────────
</span><span id=__span-3-3><a id=__codelineno-3-3 name=__codelineno-3-3 href=#__codelineno-3-3></a>annbatch          ████████████████████████████████████ 68,867
</span><span id=__span-3-4><a id=__codelineno-3-4 name=__codelineno-3-4 href=#__codelineno-3-4></a>SLAF              ████████████ 22,399
</span><span id=__span-3-5><a id=__codelineno-3-5 name=__codelineno-3-5 href=#__codelineno-3-5></a>BioNeMo SCDL      ██ 2,976
</span><span id=__span-3-6><a id=__codelineno-3-6 name=__codelineno-3-6 href=#__codelineno-3-6></a>scDataset         ██ 2,550
</span><span id=__span-3-7><a id=__codelineno-3-7 name=__codelineno-3-7 href=#__codelineno-3-7></a>TileDB (MoS)      █ 601
</span><span id=__span-3-8><a id=__codelineno-3-8 name=__codelineno-3-8 href=#__codelineno-3-8></a>AnnDataLoader      █ 411
</span><span id=__span-3-9><a id=__codelineno-3-9 name=__codelineno-3-9 href=#__codelineno-3-9></a>AnnLoader          █ 251
</span><span id=__span-3-10><a id=__codelineno-3-10 name=__codelineno-3-10 href=#__codelineno-3-10></a>─────────────────────────────────────────────────────────
</span><span id=__span-3-11><a id=__codelineno-3-11 name=__codelineno-3-11 href=#__codelineno-3-11></a>                  0   10K   20K   30K   40K   50K   60K   70K
</span></code></pre></div> <div class="admonition success"> <p class=admonition-title>SOTA Performance</p> <p>SLAF achieves <strong>8.8x higher throughput</strong> than scDataset, <strong>7.5x higher throughput</strong> than BioNeMo SCDL, <strong>37.3x higher throughput</strong> than TileDB DataLoader, <strong>54.5x higher throughput</strong> than AnnDataLoader, and <strong>89.2x higher throughput</strong> than AnnLoader in raw data loading.</p> </div> <div class="admonition info"> <p class=admonition-title>annbatch Performance Analysis</p> <p>annbatch demonstrates exceptional raw data loading performance, achieving <strong>68,867 cells/sec</strong>—<strong>3.1x higher</strong> than SLAF's throughput. This performance advantage stems from fundamental storage format differences: annbatch uses <strong>CSR (Compressed Sparse Row)</strong> format via zarr, which is optimized specifically for row-wise batch loading operations common in ML training workflows.</p> <p>SLAF, in contrast, uses <strong>COO (Coordinate)</strong> format, which provides superior flexibility across multiple use cases. This design choice reflects SLAF's broader mission: to serve as a single unified format that efficiently supports (1) low-latency cell and gene queries, (2) batch processing operations, and (3) ML training workloads—all from the same stored representation without data duplication. The COO format enables SLAF to maintain a "store once, query in place" philosophy across these diverse workloads, trading some raw loading throughput for greater versatility and query performance.</p> <p>For users whose primary use case is high-throughput ML training on pre-shuffled datasets, annbatch's CSR-based approach provides excellent performance. For users requiring a single format that supports both training and analytical queries, SLAF's COO-based architecture offers a more balanced solution.</p> </div> <div class="admonition info"> <p class=admonition-title>scDataset Performance Analysis</p> <p>Our comprehensive benchmarks reveal that scDataset achieves <strong>2,550 cells/sec</strong> with optimized parameters (<code>block_size=8</code>, <code>fetch_factor=64</code>). This performance is consistent with the system's design, though lower than our initial expectations. Note that these benchmarks use different hardware (M1 Max) than the scDataset paper's reported results (NVIDIA DGX CPU), which may account for some performance differences.</p> <p>However, we found significant limitations with multiprocessing due to pickling issues with h5py-backed AnnData objects. See our <a href=../scdataset_benchmarks/ >detailed scDataset benchmarks</a> for complete analysis including parameter scaling and multiprocessing limitations.</p> </div> <div class="admonition info"> <p class=admonition-title>Parameter Scaling Validation</p> <p>Our parameter sweeps confirm scDataset's strong scaling behavior: <strong>23.1x improvement</strong> from worst to best configuration. The <code>fetch_factor</code> parameter shows the strongest scaling (20x+ improvement), while <code>block_size</code> shows more moderate effects. This validates the design approach described in their paper, though optimal parameters may vary by hardware.</p> </div> <div class="admonition info"> <p class=admonition-title>Multiprocessing Limitations</p> <p>We were unable to test <code>num_workers &gt; 0</code> due to pickling errors with h5py objects. We're still working with the scDataset team to figure out implementation differences.</p> </div> <h3 id=tier-2-gpu-ready-output-comparison><strong>Tier 2: GPU-Ready Output Comparison</strong><a class=headerlink href=#tier-2-gpu-ready-output-comparison title="Permanent link">&para;</a></h3> <p>Raw data loading benchmarks are great, provided that we intend to train on gene expression counts directly. However, for modern foundation models like Geneformer, scGPT, Transcriptformer, or STATE, cell sentences are constructed using tokens that represent gene identity and expression bins. A lot of these workflows require dataframe-friendly operations like sorting, windowing, ranking, and filtering. Our view is that it much better to situate these computations within the (typically) CPU-bound dataloader, rather than expect the GPU in the training loop to do the heavy lifting. Accordingly, SLAF dataloaders take a tokenizer and transform raw data into training-ready token sequences.</p> <p>This GPU-ready throughput measures end-to-end performance including tokenization (that includes windowing, ranking, vocabulary mapping and padding), which is critical for training workflows involving models that turn cells into sentences.</p> <p>Even though SLAF's tokenizing dataloaders do more work (tokenization), we find that their throughput remains competitive with scDataset's raw-data dataloader, achieving comparable performance despite the additional processing overhead.</p> <table> <thead> <tr> <th>System</th> <th>Throughput (cells/sec)</th> <th>Throughput (tokens/sec)</th> </tr> </thead> <tbody> <tr> <td><strong>SLAF</strong></td> <td><strong>7,487</strong></td> <td><strong>15,332,896</strong></td> </tr> </tbody> </table> <div class="admonition success"> <p class=admonition-title>GPU-Ready Cell Sentences</p> <p>SLAF dataloaders provide the only GPU-ready input among the available alternatives.</p> </div> <h2 id=some-discrepancies><strong>Some Discrepancies</strong><a class=headerlink href=#some-discrepancies title="Permanent link">&para;</a></h2> <div class="admonition info"> <p class=admonition-title>Tokens/sec is better than Cells/sec</p> <p>Cells/sec can be a misleading metric for GPU training workloads. A better measure of throughput to minimize GPU idle time is tokens/sec, since pre-made token sequences are ready for matrix multiplication on the GPU. SLAF's tokenized mode demonstrates this principle: while cells/sec decreases due to tokenization overhead, relative to the raw mode, the constant tokens/sec across batch sizes shows that the tokenization pipeline is well-optimized across scales.</p> </div> <div class="admonition info"> <p class=admonition-title>Scaling behaviors reveal hidden optimization opportunities</p> <p>SLAF's constant scaling with batch size suggests that the loading and processing are impedance matched: loading more data per batch does not slow down throughput. Constant dataloader throughput for larger batch sizes implies that the bottleneck to batch size is not dataloading but GPU memory. In contrast, we observed that scDataset's throughput scales linearly with batch size (not shown in these results), suggesting that it is doing more work than needed at small batch sizes, and could achieve better performance with optimizations like async prefetching.</p> </div> <div class="admonition info"> <p class=admonition-title>In-memory formats matter</p> <p>The performance difference between AnnDataLoader (422 cells/sec) and scDataset (9,550 cells/sec) is dramatic. While scDataset is smarter at batching and randomization, since our benchmark tests them on loading from h5ad, it's important to compare apples to apples dataloader outputs. AnnDataLoader and AnnLoader return <code>torch.sparse_csr</code> tensors whereas scDataset returns <code>scipy.sparse.csr_matrix</code>, and these format inter-conversions represent non-zero overhead.</p> <p>In our work, we noticed different overheads for conversion from polars dataframe (SLAF's preferred format for raw data) to torch and scipy sparse formats, and ultimately decided to keep raw outputs in polars. The performance of AnnLoader and AnnDataLoader relative to scDataset is almost certainly due to the overhead of conversion from scipy sparse arrays to torch arrays and worth benchmarking more carefully to identify low-hanging fruit for optimizations in both AnnLoader and AnnDataLoader.</p> </div> <h2 id=conclusion><strong>Conclusion</strong><a class=headerlink href=#conclusion title="Permanent link">&para;</a></h2> <h3 id=cloud-native-architecture><strong>Cloud-Native Architecture</strong><a class=headerlink href=#cloud-native-architecture title="Permanent link">&para;</a></h3> <p>While these benchmarks use local SSD, the Lance format is native to cloud storage. Early tests suggest that latency between S3 and EC2 in the same region is not appreciably different from local storage. This opens up a cloud-native, store-once, query-multiple-times zero-copy architecture that eliminates data duplication.</p> <h3 id=gpu-throughput-requirements><strong>GPU Throughput Requirements</strong><a class=headerlink href=#gpu-throughput-requirements title="Permanent link">&para;</a></h3> <p>What's a good enough cells/sec rate to keep an 8×H100 node at $2/hr busy? Assuming 50 ms per training loop for a model like scGPT:</p> <ul> <li><strong>8 GPUs × 32 cells/batch × 20 batches/sec = 5,120 cells/sec</strong> would maximize GPU utilization</li> <li><strong>Tahoe-100M training</strong>: 100M cells ÷ 5,120 cells/sec = ~5.4 hours per epoch ~ $86 / epoch</li> <li><strong>Anything faster than 5,120 cells/sec</strong> opens up multi-node training possibilities, trading off cost and wall clock time.</li> </ul> <p>This raises the question: can we build towards a $100 scGPT model through efficient multi-node training enabled by high-throughput data loading? More on this soon!</p> <h3 id=high-concurrency-and-multi-user-training><strong>High Concurrency and Multi-User Training</strong><a class=headerlink href=#high-concurrency-and-multi-user-training title="Permanent link">&para;</a></h3> <p>The Lance format's high concurrency, optimized for production multimodal data lakes with high QPS, enables not only multi-node training but multiple users training multiple models simultaneously without their own copies of the dataset. This contrasts with h5ad, which requires:</p> <ol> <li><strong>Local storage</strong>: The dataset must be local to the CPU instance loading it for attached GPUs</li> <li><strong>Non-concurrent access</strong>: One copy of the dataset per user</li> </ol> <p>SLAF, with Lance under the hood, enables a truly scalable architecture for foundation model training on massive single-cell datasets.</p> <hr> <p><em>These benchmarks demonstrate SLAF's position as the leading solution for high-performance single-cell data loading, enabling efficient training of foundation models on massive datasets with minimal resource requirements and maximum scalability.</em></p> <p><em>SLAF is a young project with a bus factor of 1. You can help improve that by using it and contributing to it. Read about the <a href=blog/introducing-slaf.md>SLAF vision in this blog post</a> and contribute at <a href=https://github.com/slaf-project/slaf>github.com/slaf-project/slaf</a>.</em></p> <aside class=md-source-file> <span class=md-source-file__fact> <span class=md-icon title="Last update"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"/></svg> </span> <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date" title="November 19, 2025 20:06:19 UTC">November 19, 2025</span> </span> <span class=md-source-file__fact> <span class=md-icon title=Created> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M14.47 15.08 11 13V7h1.5v5.25l3.08 1.83c-.41.28-.79.62-1.11 1m-1.39 4.84c-.36.05-.71.08-1.08.08-4.42 0-8-3.58-8-8s3.58-8 8-8 8 3.58 8 8c0 .37-.03.72-.08 1.08.69.1 1.33.32 1.92.64.1-.56.16-1.13.16-1.72 0-5.5-4.5-10-10-10S2 6.5 2 12s4.47 10 10 10c.59 0 1.16-.06 1.72-.16-.32-.59-.54-1.23-.64-1.92M18 15v3h-3v2h3v3h2v-3h3v-2h-3v-3z"/></svg> </span> <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date" title="July 25, 2025 18:01:27 UTC">July 25, 2025</span> </span> <span class=md-source-file__fact> <span class=md-icon title=Contributors> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 4a4 4 0 0 1 4 4 4 4 0 0 1-4 4 4 4 0 0 1-4-4 4 4 0 0 1 4-4m0 10c4.42 0 8 1.79 8 4v2H4v-2c0-2.21 3.58-4 8-4"/></svg> </span> <nav> Pavan Ramkumar </nav> </span> </aside> </article> </div> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> </main> <footer class=md-footer> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2026 Pavan Ramkumar </div> </div> <div class=md-social> <a href=https://github.com/slaf-project/slaf target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"annotate": null, "base": "../..", "features": ["navigation.sections", "content.code.copy"], "search": "../../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script> <script src=../../assets/javascripts/bundle.79ae519e.min.js></script> <script src=../../javascripts/mathjax.js></script> <script src=../../javascripts/theme-reset.js></script> <script src=../../javascripts/copy-enhancement.js></script> <script src=../../javascripts/theme-aware-assets.js></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script> </body> </html>